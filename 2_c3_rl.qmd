# ML Supervisado: Regresi√≥n lineal

## M√©todos Supervisados

Un m√©todo supervisado es un tipo de t√©cnica en machine learning en la que el modelo aprende a partir de ejemplos en los que **ya conocemos la respuesta correcta**. Es decir, trabajamos con un conjunto de datos que incluye tanto las variables de entrada (lo que usamos para predecir) como una variable de salida o etiqueta (lo que queremos predecir).

![](images/supervised.jpg)

El aprendizaje se llama ‚Äúsupervisado‚Äù porque el modelo tiene un ‚Äúsupervisor‚Äù: los datos con la respuesta ya conocida. As√≠, el modelo ajusta sus **par√°metros** comparando sus predicciones con las respuestas reales y corrigiendo sus errores. Una vez entrenado, podemos darle nuevos datos (sin respuesta) y el modelo intentar√° predecir el valor de la salida.

::: callout-note
¬°NUEVO T√âRMINO!

Un **par√°metro** es un valor num√©rico que forma parte del modelo matem√°tico o estad√≠stico y que determina c√≥mo se comporta ese modelo. Los par√°metros no los escogemos ‚Äúa mano‚Äù, sino que el modelo los aprende de los datos.
:::


## Tidymodels

**tidymodels** es un conjunto de paquetes de R dise√±ado para facilitar el trabajo con **Machine Learning (ML)** dentro de un marco coherente y organizado. Su objetivo es estandarizar el proceso de modelado, desde la preparaci√≥n de datos hasta la evaluaci√≥n de resultados, utilizando la misma filosof√≠a del **tidyverse**: funciones consistentes, sintaxis clara y un enfoque centrado en los datos como tablas (`tibbles`).

![](images/tidymodels.png)

El trabajo en ML no se limita a entrenar un modelo; incluye varios pasos que deben estar bien estructurados:

- **Preparaci√≥n de datos**: limpieza, creaci√≥n de variables y transformaci√≥n de predictores.  

- **Definici√≥n del modelo**: especificar qu√© tipo de algoritmo se va a usar (regresi√≥n, √°rboles de decisi√≥n, random forest, etc.).  

- **Entrenamiento y validaci√≥n**: ajustar el modelo con los datos de entrenamiento y probarlo con datos nuevos para evitar sobreajuste. 

- **Evaluaci√≥n**: medir el desempe√±o con m√©tricas como RMSE, MAE o accuracy.  

- **Comparaci√≥n**: contrastar distintos modelos bajo un mismo flujo de trabajo.

Tidymodels organiza todo este proceso bajo un **flujo reproducible** y consistente, lo que permite:  

- Reducir errores en la preparaci√≥n de datos.  

- Comparar modelos con facilidad.  

- Mantener el c√≥digo ordenado y entendible.  


## Regresi√≥n Lineal Simple

### Recordar la ecuaci√≥n de la recta

Debemos acordarnos algunos elementos b√°sicos que aprendimos desde la escuela:

$$
y = \beta_0 + \beta_1x
$$

Donde:

y es la variable dependiente que se quiere predecir o estimar.

x es la variable independiente que se utiliza para predecir y.

Œ≤‚ÇÄ es la intersecci√≥n de la l√≠nea y.

Œ≤‚ÇÅ es la pendiente de la l√≠nea (indica cu√°nto var√≠a Y por cada unidad de X).

Tener en cuenta que si:

-   Si Œ≤‚ÇÅ es positivo, Y aumenta cuando X aumenta.Es una relaci√≥n directa / positiva.

-   Si Œ≤‚ÇÅ es negativo, Y aumenta cuando X disminuye. Es una relaci√≥n inversa / negativa.

-   Si Œ≤‚ÇÅ es cero.Y no cambia cuando X var√≠a. No existe relaci√≥n entre las variables.

### Definici√≥n

La regresi√≥n lineal es uno de los modelos m√°s simples y fundamentales dentro del aprendizaje supervisado. Su objetivo es predecir un valor **num√©rico** y **continua** a partir de una o varias variables de entrada. Se basa en la idea de que existe una relaci√≥n (aproximadamente lineal) entre esas variables explicativas y la variable que queremos predecir.

Para ello lo que hace es ajustar una l√≠nea recta (o un hiperplano, si hay varias variables) que mejor resuma la relaci√≥n entre las variables de entrada (predictoras) y la variable de salida (respuesta).

![](images/RL.jpg)


### Midiendo los errores: funci√≥n de costo

La funci√≥n de costo es una f√≥rmula matem√°tica que mide qu√© tan bien (o mal) el modelo se ajusta a los datos.  
En regresi√≥n lineal, una de las m√°s utilizadas es la **Raiz del Error Cuadr√°tico Medio (RMSE, por sus siglas en ingl√©s)**.

**Definici√≥n:**  

El RMSE mide la magnitud promedio del error en las predicciones de un modelo, penalizando m√°s los errores grandes y expres√°ndose en las mismas unidades de la variable de salida.

¬øQu√© significa?

-   Cada vez que el modelo predice un valor, podemos compararlo con el valor real.  

-   La funci√≥n de costo resume todos esos errores en un solo n√∫mero.

-   Ese n√∫mero nos indica la ‚Äúcalidad‚Äù del modelo: cuanto m√°s peque√±o sea, mejor est√° ajustada la recta a los datos.  

-   El RMSE es √∫til porque se expresa en las **mismas unidades de la variable de salida**, lo que facilita su interpretaci√≥n.


$$
J(\beta) = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \big(y_i - \hat{y}_i\big)^2}
$$

Ejemplo:

Supongamos que queremos predecir la estatura de tres personas (en cm).  

- Valores reales: 170, 180, 190  

- Predicciones: 172, 177, 189  

Errores:  

- 170 - 172 = -2

- 180 - 177 = 3

- 190 - 189 = 1

C√°lculo:  
$$
RMSE = \sqrt{\frac{(-2)^2 + (3)^2 + (1)^2}{3}} = \sqrt{\tfrac{14}{3}} \approx 2.16
$$

El modelo se equivoca en promedio **2.16** cent√≠metros.

### Explicaci√≥n vs Predicci√≥n

En el campo del an√°lisis de datos y del machine learning suele aparecer una tensi√≥n entre dos objetivos distintos: explicar fen√≥menos o predecir resultados futuros.

**Explicaci√≥n**

El objetivo principal es entender las relaciones entre las variables.

Se busca interpretar los par√°metros de un modelo: por ejemplo, c√≥mo influye la educaci√≥n en los ingresos, o qu√© efecto tiene una pol√≠tica p√∫blica en la reducci√≥n de la pobreza.

La prioridad no es tanto acertar en nuevas observaciones, sino tener coeficientes confiables y significativos que respalden **hip√≥tesis te√≥ricas**.

Se preocupa mucho por los supuestos estad√≠sticos, la validez de las inferencias, la **significancia** y la causalidad.

Ejemplo: un economista que estima un modelo para probar si la inflaci√≥n depende del precio de los metales.

![](images/vangogh1.png)

::: callout-note
Una analog√≠a al prop√≥sito de la explicaci√≥n.

El inter√©s est√° en saber si la obra refleja fielmente la realidad, es decir, si los datos o el modelo ‚Äúexplican‚Äù lo que realmente ocurri√≥. La pintura sirve como ejemplo de representaci√≥n: ¬øes una descripci√≥n precisa de lo que hab√≠a en la escena?
:::

**Predicci√≥n**

El objetivo es obtener el mayor nivel posible de acierto en datos **nuevos**.

Importa m√°s el desempe√±o predictivo que la interpretaci√≥n de los par√°metros.

Por ello que, en este √°mbito, los modelos tienen licencia para ser ‚Äúcajas negras‚Äù (random forests, redes neuronales) si eso mejora la precisi√≥n.

Se aceptan t√©cnicas como regularizaci√≥n, ensambles o validaci√≥n cruzada, que priorizan generalizaci√≥n m√°s que interpretaci√≥n.

Ejemplo: un banco que quiere predecir si un cliente dejar√° de pagar un cr√©dito, sin importar tanto cu√°les variables explican el fen√≥meno.

![](images/vangogh2.png)

::: callout-note
Una analog√≠a al prop√≥sito de la predicci√≥n

A partir del cuadro, podemos reconstruir una parte que falta (¬øpodemos ‚Äúllenar‚Äù el trozo ausente bas√°ndonos en lo que s√≠ vemos?)
:::

En estad√≠stica cl√°sica y ciencias sociales, la tendencia ha sido hacia la explicaci√≥n: probar teor√≠as y entender causalidad.

En machine learning aplicado la tendencia es hacia la predicci√≥n: lograr resultados pr√°cticos aunque el modelo no sea interpretable.


## Una regresi√≥n paso a paso

En esta secci√≥n aprenderemos, paso a paso, c√≥mo construir un modelo de machine learning utilizando regresi√≥n lineal. Veremos desde la preparaci√≥n de los datos y la definici√≥n del modelo hasta su entrenamiento, evaluaci√≥n y visualizaci√≥n de resultados, todo dentro del flujo de trabajo de tidymodels en R.

```{r}
library(tidyverse)
library(readxl)
library(tidymodels)
data <- read_xlsx("data/AML_2.xlsx")
```

Mira nuestra data, hemos identificado que tenemos ciertos pa√≠ses en los cuales NO TENEMOS la medida de aml_index, es decir, tenemos un NA.

```{r}
aml_faltante <- data |> 
  select(pais, aml_index, pobreza) |> 
  filter(is.na(aml_index))
```

```{r}
aml_faltante
```

Queremos predecir su AML_index con la variable pobreza. Por eso vamos a utilizar la data completa en la que s√≠ est√° la variable aml_index:

```{r}
data<- data |> 
        filter(!is.na(aml_index))
```

### Paso 1: An√°lisis Exploratorio de Datos (EDA)

En este punto, utilizaremos los hallazgos detectados en las √∫ltimas dos clases.

```{r}
summary(data$aml_index)
```

```{r}
summary(data$pobreza)
```

### Paso 1: Splitear la data

Dividir los datos en training y testing es un paso fundamental en machine learning. La idea es entrenar el modelo con una parte de la informaci√≥n y reservar otra parte, nunca vista por el modelo, para evaluar su capacidad de generalizar. Esto evita el sesgo de pensar que un modelo es ‚Äúbueno‚Äù solo porque se ajusta bien a los datos con los que fue entrenado.

¬øPor qu√© se hace el **split**?

üîπ Entrenamiento: el modelo aprende los patrones usando solo la porci√≥n de training.

üîπ Evaluaci√≥n: el conjunto de test sirve para medir el poder predictivo en datos nuevos.

üîπ Prevenci√≥n de sobreajuste (overfitting): si el modelo se ajusta demasiado a training, su desempe√±o en test revelar√° esa debilidad.

üîπ Realismo: simula lo que pasa en la pr√°ctica, cuando usamos el modelo para predecir casos que nunca hab√≠a visto.

üîπ Comparaci√≥n: permite elegir entre varios modelos el que realmente generaliza mejor.

```{r}
# Dividimos nuestro dataset en dos partes: training y testing
set.seed(2025)
index <- initial_split(data)     
# Crea un objeto que contiene la "partici√≥n" de los datos.
# Por defecto, 75% de las filas se van al training y 25% al testing.
# (Se puede ajustar con el argumento prop = 0.8, por ejemplo).

training_data <- training(index)  
# Extrae del split anterior la parte de entrenamiento,
# es decir, el subconjunto de datos que usaremos para
# ajustar (entrenar) nuestro modelo.

testing_data <- testing(index)    
# Extrae del split anterior la parte de prueba,
# es decir, el subconjunto de datos que NO ver√° el modelo
# durante el entrenamiento y que servir√° para evaluar
# su capacidad de generalizar a datos nuevos.
```

C√≥mo vemos las particiones creadas?

```{r}
dim(training_data)
```

```{r}
dim(testing_data)
```

### Paso 3: Preprocesamiento de datos (Feature Engineering)

El paquete recipes de tidymodels permite definir de manera ordenada y reproducible los pasos de preprocesamiento de los datos antes de entrenar un modelo de machine learning.

Primero se define la receta principal de tu modelo, que identifica la variable predicha y las predictoras, similar a una ecuaci√≥n. En este casos utilizamos esta f√≥rmula:

$$
VariablePredicha \sim Predictor
$$

Luego, si lo deseamos, podemos especificar qu√© transformaciones se aplicar√°n a las variables: desde tareas sencillas como eliminar valores perdidos o normalizar predictores, hasta imputaciones, creaci√≥n de variables dummy o reducci√≥n de dimensionalidad. Cada transformaci√≥n se a√±ade como un step, y el flujo se encarga de aprender sus par√°metros a partir del conjunto de entrenamiento y aplicarlos tambi√©n al conjunto de prueba, evitando fugas de informaci√≥n (data leakage). De esta forma, recipes ofrece un marco flexible y seguro para preparar los datos de forma consistente en todo el proceso de modelado.

Por el momento, vamos a definir nuestra **receta**:

```{r}
mi_receta <- recipe(aml_index ~ pobreza, data = training_data)
```

Luego de crear la receta, la podemos solicitar para ver qu√© es lo esta considerando:

```{r}
mi_receta
```

::: callout-note
M√°s adelante, en este paso tambi√©n vamos a poder realizar algunas transformaciones dentro de nuestras variables. Por ejemplo:

-   step_naomit() ‚Üí elimina filas con valores perdidos.

-   step_meanimpute() / step_medianimpute() ‚Üí imputan NA con la media o mediana.

-   step_modeimpute() ‚Üí imputaci√≥n de NA con la moda en variables categ√≥ricas.

-   step_dummy() ‚Üí convierte variables categ√≥ricas en variables dummy (0/1).

-   step_normalize() ‚Üí estandariza predictores (media = 0, sd = 1).

-   Entre otros.
:::

### Paso 4: Seleccionamos el modelo

En la fase de modelamiento, el primer paso es definir el modelo que utilizaremos. En este caso empleamos linear_reg(), que especifica una regresi√≥n lineal, y le asignamos un motor de c√°lculo mediante set_engine("lm").

```{r}
mi_modelo_lm <- linear_reg() |> 
                   set_engine("lm")
```

### Paso 5: Entrenamos el modelo

A continuaci√≥n, iniciamos un workflow(), que es una estructura de tidymodels dise√±ada para integrar en un solo flujo el preprocesamiento de datos (receta) y el entrenamiento. Esto garantiza que todo el proceso se ejecute de manera ordenada, reproducible y sin fugas de informaci√≥n. A√±adimos al workflow tanto la receta definida en la etapa de preprocesamiento como el modelo lineal.

```{r}
flujo_ml<-workflow() |> 
            add_recipe(mi_receta) |> 
             add_model(mi_modelo_lm)
flujo_ml
```

Finalmente, y entrenamos este flujo con los **datos de entrenamiento**. De esta manera, se obtiene un objeto ajustado que estar√° listo para realizar predicciones y ser evaluado en el conjunto de prueba.

```{r}
modelo_entrenado <- flujo_ml %>% 
                      fit(data = training_data) # Con el de ENTRENAMIENTO!
```

Si deseamos ver los coeficientes (estimates) del modelo podemos solicitarlo con `tidy()`:

```{r}
tidy(modelo_entrenado)
```

Entonces, en este caso el modelo para la predicci√≥n del AML_index ser√≠a el siguiente:

$$
AML = 4.27 + 0.04 * POBREZA
$$

### Paso 6: Evaluamos el modelo

Una vez que el modelo ha sido entrenado, el siguiente paso es evaluar su desempe√±o. La evaluaci√≥n consiste en medir qu√© tan bien el modelo logra predecir los valores de la variable de inter√©s, comparando las predicciones con los valores reales. Para ello se utilizan m√©tricas de error, como el RMSE (Root Mean Squared Error), que nos permiten cuantificar la calidad del ajuste y, sobre todo, estimar su capacidad de generalizaci√≥n cuando se aplica a nuevos datos.

Para ello, primero utilizamos el modelo generado para predecir con la nueva data:

```{r}
prediccion_test<-modelo_entrenado |> 
                  predict(testing_data) |> 
                  bind_cols(valor_real=testing_data$aml_index)
prediccion_test
```

Ahora vamos a medir c√≥mo funciona nuestro modelo utiliz√°ndolo con data de testeo. Recuerda que en nuestra data de testeo podemos validar en contraste con el valor real.

```{r}
yardstick::rmse(prediccion_test,
    truth = valor_real,
    estimate = .pred)
```

El R cuadrado es otra medida, aunque menos utilizada en machine learning, que dice cu√°nto es **explicado** por nuestro modelo.

```{r}
rsq(prediccion_test,
    truth = valor_real,
    estimate = .pred)
```

Graficamos:

```{r}
prediccion_test |> 
  ggplot()+
  aes(x = valor_real, y = .pred)+
  geom_point(color = "blue", size = 2) +
  labs(
    x = "Valor real",
    y = "Valor predicho",
    title = "Valores reales vs predicciones"
  ) +
  theme_minimal()
```

Paso 7: Colocamos el modelo en operaci√≥n

Si lo que queremos es identificar con este modelo el aml_index perdido de la data inicial, cu√°l ser√≠a nuestra predicci√≥n?

```{r}
modelo_entrenado |> 
                  predict(aml_faltante) |> 
                  bind_cols(aml_faltante$pais)
```
