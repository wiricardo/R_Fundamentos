[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para Ciencias Sociales y Gestión Pública",
    "section": "",
    "text": "Sobre el curso\n¡Bienvenidos al curso de Fundamentos de R para Ciencias Sociales y Gestión Pública!\nEste curso está diseñado para ofrecer una introducción al uso del software R desde la perspectiva de la ciencia de datos. A lo largo del curso, trabajaremos en tres ejes principales:\nPuedes leer el detalle del contenido en el sílabo del curso colgado en la plataforma del Diplomado.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliografía",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley. 2022. R for Data Science. USA. https://r4ds.hadley.nz/.",
    "crumbs": [
      "Bibliografía"
    ]
  },
  {
    "objectID": "c0_programas.html",
    "href": "c0_programas.html",
    "title": "Instalación de software",
    "section": "",
    "text": "R, un lenguaje de programación\n.R es un entorno y lenguaje de programación con un enfoque al análisis estadístico. Primero debemos instalar el R (el software estadístico), el cual lo podemos descargar en el siguiente enlace:\nHaz click aquí para descargar R\nLa versión más reciente, al 13 de junio de 2025, es la 4.5.1.\nRecuerda que R es un software libre por eso otorga a los usuarios la libertad de usar, estudiar, modificar y distribuir el código fuente. Estas libertades permiten colaboración y mejora continua del software por parte de la comunidad.",
    "crumbs": [
      "Instalación de software"
    ]
  },
  {
    "objectID": "c1_objetos.html",
    "href": "c1_objetos.html",
    "title": "1  Introducción al R",
    "section": "",
    "text": "Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#objetivos-de-la-sesión",
    "href": "c1_objetos.html#objetivos-de-la-sesión",
    "title": "1  Introducción al R",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de reconocer las características principales del programa R, incluyendo sus elementos básicos y los fundamentos para el análisis estadístico. Además, sabrá implementar los procedimientos básicos necesarios para iniciar cualquier análisis estadístico en R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#presentación",
    "href": "c1_objetos.html#presentación",
    "title": "1  Introducción al R",
    "section": "Presentación",
    "text": "Presentación",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#sobre-r",
    "href": "c1_objetos.html#sobre-r",
    "title": "1  Introducción al R",
    "section": "1.1 Sobre R",
    "text": "1.1 Sobre R\n\n1.1.1 Consideraciones básicas\nR es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos.\nR es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un número, una base de datos o un modelo estadístico.\nCada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él.\nImagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística.\n\n\n1.1.2 Dónde escribir mi código: Script\nExisten varias formas de escribir código en el R. Para ello tenemos algunas opciones simples, como el Script y otras un poco más elaboradas como Quarto.\nPara fines de esta primera clase vamos a utilizar el script, el cual es un documento de texto que tiene la peculiaridad que puede ser leídos por el programa como un manual de código. De esa forma, nosotros podemos colocar en el script los códigos de nuestro análisis, ordenarlos, comentarlos y reproducirlos en el R Studio automáticamente.\nEn suma, podemos redactar nuestros script, compartirlos con otros investigadores y ejecutarlos.\n\nComo comentario: Cuando nosotros colocamos el símbolo # al iniciar una oración, el Script lo va a identificar como un comentario del programador, como un texto que no va a ser ejecutado como código. Esto es importante porque nos permite ir comentando, por ejemplo, lo que estamos redactando en el documento. Ej: “Este código sirve para abrir un archivo”, “Aquí estoy haciendo un análisis de regresión”, entre otros.\nComo código: Cuando escribimos directamente en el documento el programa lo va a entender como código o funciones. Esto es importante tenerlo en cuenta para evitar notificaciones de Error.\n\nTe recomiendo ver el siguiente video para que puedas aprender más sobre el Script, pero también sobre las otras opciones que el R te puede ofrecer y que usaremos más adelante.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#elementos-básicos",
    "href": "c1_objetos.html#elementos-básicos",
    "title": "1  Introducción al R",
    "section": "1.2 Elementos básicos",
    "text": "1.2 Elementos básicos\n\n1.2.1 Objetos\nVamos a examinar la clase de algunos de los elementos más básicos en R.\nUn objeto puede ser un número. En este caso el objeto es de tipo numeric.\n\n5\n\n[1] 5\n\n\nO también podría ser un nombre de un país. En este caso el objeto es de tipo character. Vas a notar que se trata de un caractér porque vas a visualizar el resultado entre comillas.\n\n\"Perú\"\n\n[1] \"Perú\"\n\n\nLos objetos también pueden almacenarse en la memoria del programa con ciertos “nombres”. Por ejemplo:\n\nyear&lt;-2024\nyear\n\n[1] 2024\n\n\n\ncountry&lt;-\"Perú\"\ncountry\n\n[1] \"Perú\"\n\n\nUno puede asignar un nombre a un objeto en el R con la flecha de asignación (&lt;-)\n\n\n\n\n\n\nNota\n\n\n\nHay otro tipo de objetos conocidos como factores que los estudiaremos líneas más abajo!.\n\n\n\n\n1.2.2 Vectores\n\nUn vector es una colección de uno o más datos del mismo tipo.\nTipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico.\n\nEjemplo: Vamos a crear tres vectores: uno numérico, uno de caracter.\n\nvector_numerico &lt;- c(1, 2, 3, 4, 5)\nvector_numerico\n\n[1] 1 2 3 4 5\n\n\n\nvector_caracter &lt;- c(\"arbol\", \"casa\", \"persona\")\nvector_caracter\n\n[1] \"arbol\"   \"casa\"    \"persona\"\n\n\n\n\n1.2.3 Funciones\nUna función es como una máquina a la que le das un insumo, o input para que realice un procedimiento específico. Luego de realizar el procedimiento, la máquina te da un resultado que le vamos a llamar output.\nPor ejemplo, podemos utilizar la función sqrt() para obtener la raíz cuadrada de un número. En este caso aplicamos una función sobre un sólo número.\n\nsqrt(16)\n\n[1] 4\n\n\nPero también podemos aplicar una función sobre un vector. Por ejemplo, podemos solicitar la función sum() para obtener la suma de todos los elementos de un vector numérico:\n\nsum(vector_numerico)\n\n[1] 15\n\n\nTambién podemos utilizar la función class() para corroborar que la clase del vector que tenemos.\n\nclass(vector_numerico)\n\n[1] \"numeric\"\n\nclass(vector_caracter)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nSiempre te vas a dar cuenta que estás frente a una función porque usualmente está seguida de paréntesis en el cual se colocan los argumentos.\n\n\n\n\n1.2.4 Dataframes\nLos data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener vectores de diferentes tipos.\nEs la estructura más usada para ciencia de datos y la que vamos a ver de forma más recurrente en el curso.\nLo más importante que debes recordar es que las filas en un dataframe representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables.\nPor ejemplo, tenemos la siguiente información sobre ciertos departamentos del Perú y sus niveles de pobreza:\n\ndepartamentos&lt;-c(\"Huancavelica\", \"Ayacucho\", \"Pasco\")\npobreza&lt;-c(47.7, 46.4, 44.8)\nmi_df&lt;-data.frame(departamentos, pobreza)\nmi_df\n\n  departamentos pobreza\n1  Huancavelica    47.7\n2      Ayacucho    46.4\n3         Pasco    44.8\n\n\nUna forma de examinar rápidamente un dataframe es utilizando la función str():\n\nstr(mi_df)\n\n'data.frame':   3 obs. of  2 variables:\n $ departamentos: chr  \"Huancavelica\" \"Ayacucho\" \"Pasco\"\n $ pobreza      : num  47.7 46.4 44.8\n\n\nEl output de esta función te indica las dimensiones del dataframe (número de observaciones y número de variables), así como los nombres de las variables, el tipo y algunos valores de muestra.\nOtra función básica para explorar es names(), la cual te arroja exclusivamente los nombres de las variables del dataframe:\n\nnames(mi_df)\n\n[1] \"departamentos\" \"pobreza\"      \n\n\n\n\n\n\n\n\nImportante\n\n\n\nUn error frecuente es no identificar correctamente las unidades de análisis con las que estamos trabajando. Al abrir un conjunto de datos, lo primero que debes preguntarte es: ¿A qué se refiere esta información? ¿A personas, países, instituciones?\n\n\n\n\n1.2.5 Índices\n\nUsar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos.\nUn índice en R representa una posición.\nCuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella.\n\nEjemplos:\n\nSeleccionar la columna 2:\n\n\nmi_df [,2]\n\n[1] 47.7 46.4 44.8\n\n\nPara seleccionar una columna, también podemos usar el símbolo de $.\n\nmi_df$pobreza\n\n[1] 47.7 46.4 44.8\n\n\nNormalmente lo usamos cuando queremos aplicar una función a sólo una columna. Como por ejemplo:\n\nmean(mi_df$pobreza)\n\n[1] 46.3\n\n\n\nSeleccionar sólo el caso (fila) 2:\n\n\nmi_df [2,]\n\n  departamentos pobreza\n2      Ayacucho    46.4\n\n\n\nSeleccionar el elemento que se encuentra en la fila 2 y la columna 2:\n\n\nmi_df [2,2]\n\n[1] 46.4\n\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que en los [,] primero se mencionan las filas y luego las columnas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#procedimientos-básicos",
    "href": "c1_objetos.html#procedimientos-básicos",
    "title": "1  Introducción al R",
    "section": "1.3 Procedimientos básicos",
    "text": "1.3 Procedimientos básicos\nHasta aquí hemos aprendido los elementos básicos del R, ahora procederemos a analizar los procedimientos más cotidianos que realizaremos en un proceso de análisis de datos estadísticos.\n\n1.3.1 Apertura de paquetes\nLíneas arriba te había comentado que existían funciones que podías aplicar sobre objetos en el R. Dabas un input y la función te arrojaba un determinado resultado.\nAhora bien, lo más interesante del R es que existen diferentes “conjuntos de funciones” para tareas específicas y que uno puede instalar y utilizar en tu proceso de análisis.\nPara instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete).\nHagamos la prueba con el paquete rio, el cual es un paquete creado para importar/exportar archivos de diversos tipos.\nPrimero lo vamos a instalar. No te olvides que cuando instalas un paquete el nombre del mismo va entre comillas:\n\n#install.packages(\"rio\")\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que la instalación de paquetes se realiza sólo una vez. Esto quiere decir que si instalas hoy el paquete “rio” ya no será necesario que realices esta operación nuevamente.\n\n\nLuego de instalarlo lo debemos abrir para utilizar las funciones que están dentro de él.\n\nlibrary(rio)\n\n\n\n1.3.2 Apertura de archivos\nLo más común es que se te va a entregar un archivo para que lo puedas abrir en el R.\nPara ello, una primera forma sencilla de abrir un archivo es haciendo uso de la función import del paquete rio:\n\ndata&lt;-import(\"data/regiones.xlsx\") \n#Dentro del () colocas la ubicación del archivo.\n\nUna vez que abrimos una data y corroboramos que está en nuestro Environment podemos explorarla.\nViendo un encabezado de las primeras filas:\n\nhead(data)\n\n     region macroregion poblacion pobreza nivel_pobreza  agua desague\n1  Amazonas     Oriente    379384    47.3             3 51.84   36.69\n2    Ancash       Norte   1083519    23.5             2 71.56   56.38\n3  Apurímac         Sur    405759    42.8             3 56.33   36.12\n4  Arequipa         Sur   1382730     9.1             1 72.47   65.85\n5  Ayacucho         Sur    616176    51.9             3 66.99   45.35\n6 Cajamarca       Norte   1341012    52.9             3 52.89   32.48\n  electrificacion acceso_internet telefonia_movil pc_tablet hospitales\n1           73.67            4.45           69.39     11.02          8\n2           85.20           18.33           79.60     25.00         23\n3           80.43            8.93           71.21     14.74          8\n4           89.98           32.88           91.28     40.52         24\n5           80.94           10.42           77.65     17.84         11\n6           80.68            9.29           74.66     14.10         25\n\n\nAnalizando su estructura:\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : chr  \"Oriente\" \"Norte\" \"Sur\" \"Sur\" ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : num  3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...\n\n\n\nnames(data)\n\n [1] \"region\"          \"macroregion\"     \"poblacion\"       \"pobreza\"        \n [5] \"nivel_pobreza\"   \"agua\"            \"desague\"         \"electrificacion\"\n [9] \"acceso_internet\" \"telefonia_movil\" \"pc_tablet\"       \"hospitales\"     \n\n\n\n\n1.3.3 Identificación teórica de la variable\n\nAntes de seguir en el análisis debemos corroborar los tipos de variables con los que estamos trabajando a nivel teórico.\nEn una data real, esto normalmente lo encontramos en el Cuestionario o Diccionario de Variables. Según la teoría estadistica podemos tener dos grandes opciones.\n\n1.3.3.1 Numéricas\nLas variables numéricas son aquellas que representan cantidades medidas o contadas, y pueden ser de tipo entero o decimal. Permiten realizar operaciones matemáticas y son fundamentales en el análisis estadístico y cuantitativo.\nSe clasifican en continuas y discretas, basándose en los valores que pueden tomar.\nLas variables discretas representan información que se puede contar en unidades enteras, como el número de hospitales en nuestra base de datos.\nPor otro lado, las variables continuas pueden tomar cualquier valor dentro de un rango, incluyendo decimales. En nuestra base de datos contamos con variables como * como la altura o el peso pobreza, agua, entre otros. Esto significa que pueden medir con precisión infinita dentro de su escala, adaptándose a una variedad más amplia de datos y mediciones.\n\n\n1.3.3.2 Categóricas\nUna variable categórica clasifica las observaciones en grupos o categorías que no tienen un orden matemático inherente. Se dividen en nominales y ordinales.\nLas variables nominales representan categorías sin un orden específico entre ellas, como colores, nombres de países o géneros. En nuestra data una variable nominal sería macroregion.\nEn cambio, las variables ordinales sí poseen un orden o jerarquía entre las categorías, aunque la distancia entre estas no es necesariamente uniforme; por ejemplo, niveles de educación o calificaciones de satisfacción. Continuando con el ejemplo, la variable ordinal nivel_pobreza clasifica en categorías donde el 1 corresponde a “Bajo”, el 2 a “Medio” y el 3 a “Alto”.\n\n\n\n1.3.4 Configuración de las variable en R\nAhora veamos qué tenemos en nuestra data.\nVeamos las siguientes tres variables: poblacion (numérica), macroregión (nominal) y nivel de pobreza (ordinal).\nDichas variables qué tipo de objeto son actualmente en el R?\n\n1.3.4.1 Numeric\n\nclass(data$poblacion)\n\n[1] \"numeric\"\n\n\nPara el caso de población cuenta con la configuración adecuada pues es numeric.\nTen en cuenta que para el caso de una variable numérica discreta como hospitales la configuración adecuada también es numeric.\n\n\n1.3.4.2 Factors\nPara el caso de las variables categóricas, para poder trabajar con estas en el R debemos convertirlas a un tipo especial de objeto denominado factor.\nBásicamente, un factor es una variable que tiene grupos, los cuales pueden estar ordenados o no ordenados.\nFACTORES NO ORDENADOS\nPara el caso de la variable nominal macroregión que inicialmente está mal configurada (pues tiene el tipo character).\n\nclass(data$macroregion)\n\n[1] \"character\"\n\n\nvamos a convertirla en un factor no ordenado.\n\ndata$macroregion&lt;-factor(data$macroregion)\n\n\n\n\n\n\n\nTip\n\n\n\nHemos empleado la función factor() y el operador de asignación porque estamos modificando una parte de nuestro conjunto de datos. En otras palabras, estamos actualizando la variable macroregión con su configuración correcta.\n\n\nPodemos corroborar el tipo final pidiendo otra vez la función str():\n\nstr(data$macroregion)\n\n Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n\n\nEn este caso nos menciona que ahora la variable macroregion es un factor con cuatro niveles (Centro, Norte, Sur, Oriente).\n\n\n\n\n\n\nImportante\n\n\n\nSi bien aquí vemos la palabra “niveles” esto no quiere decir que para R esos niveles tengan un orden, sino más bien que son categorías diferentes.\n\n\nFACTORES ORDENADOS\nAhora bien, el caso del nivel de pobreza es diferente, ya que, aunque también es un factor, sus niveles presentan un orden de magnitud específico.\nEn este caso, además de convertirla en factor, es necesario especificar el orden de los niveles, indicando que efectivamente se trata de una secuencia ordenada.\n\ndata$nivel_pobreza&lt;-factor(data$nivel_pobreza,\n                          levels = c(1,2,3),\n                          ordered = TRUE)\n\nMediante la función str(), confirmamos que nuestra variable nivel_pobreza se ha convertido efectivamente en un factor ordenado con tres niveles, donde 1 es menor que 2 y, a su vez, 2 es menor que 3.\n\nstr(data$nivel_pobreza)\n\n Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n\n\n\n\n\n\n\n\nImportante\n\n\n\nAunque para nosotros los niveles parecen ser números (1, 2 o 3), para R no lo son. Esto significa que no es posible realizar operaciones matemáticas con ellos.\n\n\nAhora con esta configuración ya estamos listos para el siguiente paso: manipular tablas y calculas estadísticos descriptivos.\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "c1_objetos.html#ficha-resumen-cheat-sheet",
    "href": "c1_objetos.html#ficha-resumen-cheat-sheet",
    "title": "1  Introducción al R",
    "section": "1.4 Ficha resumen (Cheat Sheet)",
    "text": "1.4 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al R</span>"
    ]
  },
  {
    "objectID": "index.html#sistema-de-evaluación",
    "href": "index.html#sistema-de-evaluación",
    "title": "Fundamentos de R para Ciencias Sociales y Gestión Pública",
    "section": "Sistema de evaluación",
    "text": "Sistema de evaluación\nLa evaluación del curso está compuesta por tres componentes:\nTRABAJO FINAL: REPORTE ANALÍTICO (50%)\n\nSe realizará de forma grupal.\nCada grupo seleccionará un tema de interés y aplicará a una base de datos de su elección cada uno de los temas vistos en el curso: importación, manipulación y transformación de datos, visualización y elaboración de un reporte analítico.\nAl finalizar el curso cada grupo entregará un código en R Markdown (que deberá poder ser reproducido por el docente) así como un reporte (HTML).\nImportantes: para garantizar una evaluación justa y transparente, cada grupo deberá presentar, al final de su proyecto, un breve informe de contribuciones individuales (no más de 10 líneas). Este informe debe detallar las responsabilidades y tareas específicas asumidas por cada miembro del equipo. Si se diera el caso de que un miembro no ha participado de manera adecuada o ha habido una falta significativa de contribución, esto debe ser comunicado explícitamente en el informe.\n\nEJERCICIOS PRÁCTICOS (30%)\n\nLos ejercicios prácticos son evaluaciones asincrónicas que se realizarán de forma individual.\nEstas evaluaciones tendrán un plazo de entrega de una semana.\nConsistirán en la aplicación del contenido visto en clase en una data particular, sea provista por el docente o propuesto por el estudiante.\n\nPARTICIPACIÓN EN CLASE (20%)\n\nLa participación en clase es evaluada considerando tanto la frecuencia como la calidad de las contribuciones de los estudiantes, de forma individual.\nSe realizará utilizando plataformas para realizar evaluaciones rápidas al finalizar cada semana, las cuales incluirán mayormente preguntas teóricas.\nEstas evaluaciones tendrán un plazo de entrega de 1 día.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "c0_programas.html#r-studio",
    "href": "c0_programas.html#r-studio",
    "title": "Instalación de software",
    "section": "R Studio",
    "text": "R Studio\n\nRStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R. Facilita el trabajo con R al proporcionar una interfaz gráfica amigable que incluye un editor de código avanzado, herramientas de depuración, visualización de datos y gestión de paquetes, lo que optimiza y simplifica el proceso de análisis de datos y programación estadística.\nLo puedes descargar desde el siguiente link:\nHaz click aquí para descargar R Studio\n\n\n\n\n\n\nAdvertencia\n\n\n\n¡Recuerda que primero debes instalar R y luego R Studio!",
    "crumbs": [
      "Instalación de software"
    ]
  },
  {
    "objectID": "c0_programas.html#manual-de-instalación-de-r-y-r-studio",
    "href": "c0_programas.html#manual-de-instalación-de-r-y-r-studio",
    "title": "Instalación de software",
    "section": "Manual de instalación de R y R Studio",
    "text": "Manual de instalación de R y R Studio\nTe sugiero ver el siguiente video para que puedas instalar los programas en tu computadora:",
    "crumbs": [
      "Instalación de software"
    ]
  },
  {
    "objectID": "c0_programas.html#quarto",
    "href": "c0_programas.html#quarto",
    "title": "Instalación de software",
    "section": "Quarto",
    "text": "Quarto\n\nQuarto es una plataforma de publicación que permite crear documentos reproducibles, combinando texto, código y resultados de análisis en un solo documento.\nEs especialmente útil para científicos de datos, analistas y académicos, ya que soporta múltiples lenguajes de programación como R, Python y Julia.\nQuarto facilita la creación de informes, presentaciones, sitios web y más, integrando visualizaciones y análisis de datos de manera dinámica y reproducible.\nLo puedes descargar desde el siguiente link:\nHaz click aquí para descargar Quarto",
    "crumbs": [
      "Instalación de software"
    ]
  },
  {
    "objectID": "index.html#sobre-trabajo-final",
    "href": "index.html#sobre-trabajo-final",
    "title": "R para Ciencias Sociales y Gestión Pública",
    "section": "Sobre trabajo final",
    "text": "Sobre trabajo final",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "c2_manipulacion.html",
    "href": "c2_manipulacion.html",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "Objetivos de la sesión",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#objetivos-de-la-sesión",
    "href": "c2_manipulacion.html#objetivos-de-la-sesión",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de manipular un dataframe a fin de editarlo de acuerdo a su necesidad utilizando algunos verbos básicos del paquete dplyr. También podrá solicitar algunos de los principales estadísticos descriptivos de tendencia central.",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#presentación",
    "href": "c2_manipulacion.html#presentación",
    "title": "2  Manipulación de tablas",
    "section": "Presentación",
    "text": "Presentación",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#introducción-al-tidyverse",
    "href": "c2_manipulacion.html#introducción-al-tidyverse",
    "title": "2  Manipulación de tablas",
    "section": "2.1 Introducción al Tidyverse",
    "text": "2.1 Introducción al Tidyverse\nEl tidyverse es una colección de paquetes de R diseñados para la ciencia de datos que comparten una filosofía subyacente y son interoperables, facilitando la importación, manipulación, exploración y visualización de datos.\nTe sugiero ver este video introductorio sobre el Tidyverse:\n\nAbrimos la librería tidyverse:\n\nlibrary(tidyverse)\nlibrary(rio)",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#manipulación-de-datos-con-dplyr",
    "href": "c2_manipulacion.html#manipulación-de-datos-con-dplyr",
    "title": "2  Manipulación de tablas",
    "section": "2.2 Manipulación de datos con dplyr",
    "text": "2.2 Manipulación de datos con dplyr\ndplyr es un paquete del Tidyverse que sirve para manipular tablas y transformarlas. Tiene una amplia gama de verbos con los cuales podemos realizar las tareas más recurrentes de la manipulación de datos.\n\n\n2.2.1 Problema de investigación y data\n\nEl Índice de Percepción de la Corrupción (CPI, por sus siglas en inglés) es una herramienta global que clasifica a los países según la percepción de corrupción en el sector público, basándose en evaluaciones de expertos y encuestas de negocios. La escala va de 0 (muy corrupto) a 100 (muy limpio), y sirve para comparar la situación de corrupción entre diferentes naciones. Es publicado anualmente por Transparency International, una organización no gubernamental dedicada a combatir la corrupción global.\nExaminemos la base original. Vamos a editar la tabla con diversos verbos de dplyr.\nAbrir archivo\nAbrimos el archivo con el paquete `rio``:\n\nlibrary(rio)\ndata_con_rio&lt;-import(\"data/CPI.xlsx\")\n\nTen en cuenta que en el R también existen otros paquetes como readr, haven o readxl que también te permiten abrir archivos de distintos formatos.\nPor ejemplo, podríamos abrir este archivo con la función read_xlsx():\n\nlibrary(readxl)\ndata&lt;-read_xlsx(\"data/CPI.xlsx\")\n\nPodemos ver las datas (y las diferencias que trae abrirlas con uno u otro paquete):\n\n#data_con_rio\nclass(data_con_rio)\n\n[1] \"data.frame\"\n\n\n\ndata\n\n# A tibble: 1,086 × 5\n   country               year iso3  region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AFG   AP            24\n 2 Albania               2022 ALB   ECA           36\n 3 United Arab Emirates  2022 ARE   MENA          67\n 4 Angola                2022 AGO   SSA           33\n 5 Argentina             2022 ARG   AME           38\n 6 Armenia               2022 ARM   ECA           46\n 7 Australia             2022 AUS   AP            75\n 8 Austria               2022 AUT   WE/EU         71\n 9 Azerbaijan            2022 AZE   ECA           23\n10 Bahamas               2022 BHS   AME           64\n# ℹ 1,076 more rows\n\nclass(data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n\n\n\nNota\n\n\n\nUn tibble es una versión moderna del dataframe en R, parte del tidyverse, diseñado para facilitar el trabajo con datos tabulares.\n\n\nExploración del dataset y configuración de variables\nVemos la estructura rápidamente:\n\nstr(data)\n\ntibble [1,086 × 5] (S3: tbl_df/tbl/data.frame)\n $ country  : chr [1:1086] \"Afghanistan\" \"Albania\" \"United Arab Emirates\" \"Angola\" ...\n $ year     : num [1:1086] 2022 2022 2022 2022 2022 ...\n $ iso3     : chr [1:1086] \"AFG\" \"ALB\" \"ARE\" \"AGO\" ...\n $ region   : chr [1:1086] \"AP\" \"ECA\" \"MENA\" \"SSA\" ...\n $ cpi_score: num [1:1086] 24 36 67 33 38 46 75 71 23 64 ...\n\n\nAl ejecutar names() sobre un conjunto de datos, se nos devuelve un vector con los nombres de todas las columnas en el orden en que aparecen.\n\nnames(data)\n\n[1] \"country\"   \"year\"      \"iso3\"      \"region\"    \"cpi_score\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nAntes de proseguir con el análisis descriptivo, es fundamental que comprendas claramente qué representan las filas y las columnas en tus datos.\n\n\nCorroboramos que el score del CPI esté adecuadamente configurado.\n\nclass(data$cpi_score)\n\n[1] \"numeric\"\n\n\nDe acuerdo, podemos proseguir.\n\n\n2.2.2 Select()\nLa función select() es utilizada para seleccionar o excluir columnas de un data frame o tibble en R. Va más allá de simplemente escoger columnas por nombre, ya que permite una amplia gama de criterios y operaciones.\nFuncionamiento básico:\n\nEntrada: Un data frame o tibble y un conjunto de nombres de columnas o criterios para seleccionar columnas.\nSalida: Un objeto de la misma clase que el de entrada (data frame o tibble) que contiene solo las columnas seleccionadas.\n\nVamos a seleccionar sólo ciertas columnas:\n\ndata1&lt;-data |&gt; \n  select(country, year, region, cpi_score)\ndata1\n\n# A tibble: 1,086 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 1,076 more rows\n\n\nTener en cuenta que puedes:\n\nSeleccionar por nombre\nSeleccionar por el número de la columna\n(Des)seleccionar colocando un “-” antes del nombre/número de columna.\nSeleccionar un rango colocando por ejemplo 2:4 lo que significa “desde la columna 2 hasta la columna 4).\nPuedes combinar todas las anteriores y tener más de un criterio a la vez separándolo por coma.\n\n\n\n2.2.3 Filter()\nLa función filter() se utiliza para filtrar filas de un data frame o tibble en R en función de condiciones específicas, permitiendo crear un subconjunto de datos.\nAl crear subconjuntos nuestros datos de forma precisa, podemos focalizar nuestro análisis, mejorar la eficiencia computacional y obtener resultados más claros y relevantes.\nCaracterísticas principales:\n\nCondiciones múltiples: Puedes usar múltiples condiciones para filtrar tus datos. Estas se combinan utilizando operadores lógicos como & (y), | (o) y ! (no).\nUso de operadores de comparación: Los operadores estándar como ==, &gt;, &lt;, &gt;=, &lt;=, y != se utilizan para establecer condiciones.\nFunciones auxiliares: dplyr proporciona funciones como between(), que pueden ser útiles para establecer condiciones. Por ejemplo, between(x, 1, 10) es equivalente a x &gt;= 1 & x &lt;= 10.\n\nEn este caso vamos a seleccionar aquellos países cuya medición es del año 2022.\n\ndata2&lt;-data1 %&gt;%                   \n  filter(year==2022)\ndata2\n\n# A tibble: 181 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 171 more rows\n\n\n\n\n2.2.4 Arrange()\nSe utiliza para ordenar (o reordenar) un data frame o tibble según una o más columnas.\nFuncionamiento básico:\n\nOrdenación simple: Si proporcionas una columna a arrange(), ordenará el data frame en función de esa columna en orden ascendente por defecto.\nOrdenación descendente: Si deseas ordenar en dirección descendente, puedes usar la función desc(). Por ejemplo: df |&gt; arrange(desc(edad)) ordenará el data frame por la columna “edad” en orden descendente.\nOrdenación múltiple: Puedes proporcionar múltiples columnas para ordenar, y arrange() las usará en el orden proporcionado para determinar el ordenamiento. Por ejemplo, si deseas ordenar primero por “grupo” y luego por “edad” dentro de cada grupo, usarías: df |&gt; arrange(grupo, edad).\n\n\ndata3&lt;-data2 |&gt;    \n  arrange(desc(cpi_score))\ndata3\n\n# A tibble: 181 × 4\n   country      year region cpi_score\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90\n 2 Finland      2022 WE/EU         87\n 3 New Zealand  2022 AP            87\n 4 Norway       2022 WE/EU         84\n 5 Singapore    2022 AP            83\n 6 Sweden       2022 WE/EU         83\n 7 Switzerland  2022 WE/EU         82\n 8 Netherlands  2022 WE/EU         80\n 9 Germany      2022 WE/EU         79\n10 Ireland      2022 WE/EU         77\n# ℹ 171 more rows\n\n\n\n\n2.2.5 Mutate()\nLa función mutate() está diseñada para crear o modificar columnas dentro de un data frame o tibble en R. Mientras que el data frame original se mantiene inalterado, mutate() devuelve una copia con las columnas especificadas añadidas o alteradas.\nEn este caso vamos a crear una variable cambiando la escala del score del CPI.\nEn la medida original 0 representaba alta corrupción y 100 escasa corrupción. Ahora, si realizamos la operación “100 - cpi_score”, los valores cercanos a 0 tendrán poca corrupción y los cercanos a 100 alta corrupción, siendo más intuitivo.\nEsta transformación puede ser útil para ajustar la interpretación de los datos a contextos donde es más intuitivo trabajar con escalas donde un número mayor indica mayor intensidad de un fenómeno (Corrupción, en este caso), dependiendo del análisis que se desea realizar.\n\ndata4&lt;-data3 |&gt;   \n  mutate(cpi_score2=100-cpi_score) \ndata4\n\n# A tibble: 181 × 5\n   country      year region cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90         10\n 2 Finland      2022 WE/EU         87         13\n 3 New Zealand  2022 AP            87         13\n 4 Norway       2022 WE/EU         84         16\n 5 Singapore    2022 AP            83         17\n 6 Sweden       2022 WE/EU         83         17\n 7 Switzerland  2022 WE/EU         82         18\n 8 Netherlands  2022 WE/EU         80         20\n 9 Germany      2022 WE/EU         79         21\n10 Ireland      2022 WE/EU         77         23\n# ℹ 171 more rows\n\n\n\n\n2.2.6 Summarise()\nSe utiliza para crear resúmenes estadísticos de un data frame o tibble.\nDentro de los resúmenes puedes disponer de por ejemplo:\nMedidas de tendencia central: Estas funciones describen un valor central o típico dentro de un conjunto de datos.\n\nMedia: mean(x)\nMediana: median(x)\n\nCómo calcularíamos la media de forma directa (tradicional)?\n\nsummary(data4$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué significa NA´s? ¿Por qué se produce esto en una data como la de Corruption Perception Index?\n\n\nCómo lo calculamos con tidyverse?\n\ndata4 |&gt;   \n  summarise(mean(cpi_score2, na.rm = T))    \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nNota\n\n\n\nCuando aplicamos un summarise lo que nos devuelve es un valor o conjunto de valores. Por otro lado, el argumento na.rm = TRUE se utiliza para especificar que los valores perdidos (NA) deben ser ignorados en el cálculo. De esta forma, le indicamos a la función que proceda con la operación excluyendo dichos valores ausentes.\n\n\n\n\n2.2.7 Utilizando pipe: |&gt;\nProbablemente hayas observado que hemos creado un conjunto de datos para cada verbo utilizado, lo cual en situaciones reales resultaría excesivamente repetitivo. Haciendo una analogía con la escritura de un libro, sería como si estuviéramos limitados a usar únicamente oraciones, lo cual haría el proceso tedioso.\nEl operador |&gt; (pipe) en R, introducido en la versión 4.1, permite realizar operaciones en cadena, facilitando la secuencia de funciones y transformaciones en un flujo más legible y ordenado.\nEs evidente que, mediante el uso del operador pipe, podemos encadenar verbos de manera fluida y evitar la creación innecesaria de objetos, ya que este operador permite que el resultado a la izquierda se convierta automáticamente en el argumento de la función a la derecha.\n\ndata |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt; \n  arrange(desc(cpi_score)) |&gt; \n  mutate(cpi_score2=100-cpi_score) |&gt; \n  summarise(mean(cpi_score2, na.rm=T))  \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué sucede si a esta cadena de pipes le doy un nombre? ¿Cuál sería el objeto creado?\n\n\n\ndata_final&lt;-data |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt;\n  arrange(desc(cpi_score)) |&gt;\n  mutate(cpi_score2=100-cpi_score)",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#funciones-complementarias",
    "href": "c2_manipulacion.html#funciones-complementarias",
    "title": "2  Manipulación de tablas",
    "section": "2.3 Funciones complementarias",
    "text": "2.3 Funciones complementarias\n\n2.3.1 Agrupando con group_by()\nSe utiliza para dividir un conjunto de datos en grupos según valores de una o más variables (normalmente de tipo categórica). Una vez que los datos están agrupados, es posible realizar operaciones específicas dentro de cada grupo.\n\ndata |&gt;   \n  group_by(year) |&gt; \n  summarise(Media=mean(cpi_score, na.rm = T)) \n\n# A tibble: 6 × 2\n   year Media\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2017  43.1\n2  2018  43.1\n3  2019  43.2\n4  2020  43.3\n5  2021  43.3\n6  2022  43.0\n\n\n\n\n2.3.2 Contar con count()\nFacilita el conteo de observaciones dentro de categorías específicas de una o más variables en un dataframe. Esta función agrupa el conjunto de datos por las variables especificadas y luego calcula el número de observaciones dentro de cada categoría, retornando un nuevo dataframe con las categorías y sus respectivos conteos. Es una herramienta esencial para obtener resúmenes rápidos y frecuencias de variables categóricas en datos estructurados.\n\ndata_final |&gt;   \n  count(region) |&gt;  \n  arrange(desc(n))  \n\n# A tibble: 6 × 2\n  region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 SSA       49\n2 AME       32\n3 AP        32\n4 WE/EU     31\n5 ECA       19\n6 MENA      18\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn la última línea de código, indicamos a R que ordene los datos de acuerdo a la variable ‘n’, la cual fue definida en la línea de código precedente. Es importante recordar que la ejecución de acciones o funciones en R se realiza de manera secuencial y acumulativa.\n\n\n\n\n2.3.3 Renombrar con rename()\nPermite cambiar los nombres de las columnas de un dataframe. Para ello, se especifica el nuevo nombre deseado y el nombre actual de la columna. Esta función es útil cuando se necesita ajustar o estandarizar los nombres de las columnas en un conjunto de datos, facilitando así análisis posteriores y asegurando la claridad y consistencia en la manipulación de los datos.\nPrimero debes escribir el nuevo nombre y luego el nombre original de la variable.\n\ndata_final |&gt;   \n  rename(zona=region)   # Renombro la columna \"region\" (nombre original) como \"zona\" (nombre nuevo)\n\n# A tibble: 181 × 5\n   country      year zona  cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU        90         10\n 2 Finland      2022 WE/EU        87         13\n 3 New Zealand  2022 AP           87         13\n 4 Norway       2022 WE/EU        84         16\n 5 Singapore    2022 AP           83         17\n 6 Sweden       2022 WE/EU        83         17\n 7 Switzerland  2022 WE/EU        82         18\n 8 Netherlands  2022 WE/EU        80         20\n 9 Germany      2022 WE/EU        79         21\n10 Ireland      2022 WE/EU        77         23\n# ℹ 171 more rows\n\n\n\n\n2.3.4 Recodificar con case_when()\nLa función case_when() del paquete tidyverse en R sirve para recodificar datos y crear nuevas variables o modificar variables existentes basándose en múltiples condiciones.\nPermite evaluar varias condiciones utilizando una sintaxis similar a una instrucción “if-else”. Esta función es particularmente útil cuando necesitamos recodificar una variable en varias categorías o cuando tenemos múltiples condiciones a evaluar.\nSe coloca primero la condición (fórmula) seguido del símbolo ~ (alt+126) y la etiqueta.\nAl final se coloca TRUE, lo que indica todos aquellos casos que no cumplen con las condiciones anteriores.\n\n\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\ndata_final&lt;-data_final |&gt; \n            drop_na(cpi_score2)\n            summary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   45.00   60.50   57.02   70.25   88.00 \n\n\nPodemos realizar:\n\ndata_final&lt;-data_final  |&gt;   \n  mutate(corrupcion=case_when(cpi_score2&lt;30~\"Bajo\", \n                              cpi_score2&lt;60~\"Medio\", \n                              cpi_score2&lt;=100~\"Alto\")) \n\nLe asignamos la configuración adecuada:\n\ndata_final$corrupcion&lt;-factor(data_final$corrupcion,\n                          levels = c(\"Bajo\", \"Medio\", \"Alto\"),\n                          ordered = TRUE)\n\nFinalmente, ya contamos una nueva nueva variable ordinal creada a partir de una variable numérica:\n\nstr(data_final$corrupcion)\n\n Ord.factor w/ 3 levels \"Bajo\"&lt;\"Medio\"&lt;..: 1 1 1 1 1 1 1 1 1 1 ...",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c2_manipulacion.html#ficha-resumen-cheat-sheet",
    "href": "c2_manipulacion.html#ficha-resumen-cheat-sheet",
    "title": "2  Manipulación de tablas",
    "section": "2.4 Ficha resumen (Cheat Sheet)",
    "text": "2.4 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "Fundamentos de R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html",
    "href": "c3_visualizacion.html",
    "title": "3  Visualización de datos",
    "section": "",
    "text": "3.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#objetivos-de-la-sesión",
    "href": "c3_visualizacion.html#objetivos-de-la-sesión",
    "title": "3  Visualización de datos",
    "section": "",
    "text": "Tras familiarizarnos con los principios básicos de la programación en R y la manipulación de sus elementos clave, nos centraremos en la visualización de datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#base-de-datos",
    "href": "c3_visualizacion.html#base-de-datos",
    "title": "3  Visualización de datos",
    "section": "3.2 Base de datos",
    "text": "3.2 Base de datos\nDisponemos de una base de datos que incluye una variedad de indicadores e índices para 95 países alrededor del mundo.\nLos datos abarcan: País, Continente, Región, Índice, Índice de Lavado de Activos, Matrícula, PBI per cápita, Pobreza Urbano, Gasto en educación, Índice de Percepción de la Corrupción, Estado de derecho, Índice de Democracia, Categoría del Índice de Democracia, Índice de Crimen Organizado.\n\nlibrary(tidyverse)\nlibrary(readxl)\ndata&lt;-read_xlsx(\"data/AML.xlsx\")\n\nVeamos la data rápidamente:\n\nhead(data)\n\n# A tibble: 6 × 14\n  Pais       Continent Region AML_Index Matricula  PBIPC Pobreza URBANO gastoedu\n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Afghanist… Asia      South… No se de…      50.1   552.    54.5   26       4.06\n2 Albania    Europe    Centr… 4.75           86.6  5224.    14.3   62.1     2.47\n3 Angola     Africa    Centr… 7.03           11.3  3437.    36.6   66.8     3.42\n4 Argentina  Americas  South… No se de…      90.8 11688.    25.7   92.1     5.46\n5 Armenia    Asia      Centr… 4.72           87.7  4212.    32     63.3     2.71\n6 Austria    Europe    Weste… 4.099999…      87   51230.     3     58.7     5.5 \n# ℹ 5 more variables: CPI_Index &lt;dbl&gt;, Rule_of_Law &lt;dbl&gt;,\n#   Democracy_Index &lt;dbl&gt;, Democracy_Index_cat &lt;chr&gt;,\n#   Organized_Crime_Index &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#anatomía-de-un-ggplot",
    "href": "c3_visualizacion.html#anatomía-de-un-ggplot",
    "title": "3  Visualización de datos",
    "section": "3.3 Anatomía de un ggplot",
    "text": "3.3 Anatomía de un ggplot\n\nggplot2 es un popular paquete de visualización de datos para el lenguaje de programación R, basado en los principios de la “Gramática de Gráficos”. Esta filosofía de diseño permite a los usuarios construir gráficos complejos y estéticamente agradables a partir de componentes básicos de forma intuitiva y flexible.\nEl núcleo de ggplot2 radica en su sistema de capas, donde cada gráfico se construye agregando capas que pueden incluir, entre otros, los datos, las estéticas (como color, forma y tamaño), los objetos geométricos (como puntos, líneas y barras), las escalas, y las anotaciones. Este enfoque modular no solo facilita la personalización y optimización de los gráficos sino que también promueve una estructura de código clara y comprensible.\nVamos a hacer un ejemplo paso a paso:\n\n3.3.1 Datos\nEs el conjunto de datos a visualizar.\nNuestra primera capa siempre va a ser la data. Sobre esta iniciamos la función ggplot y corroboramos que tenemos un lienzo en blanco.\n\ndata |&gt; \n  ggplot()\n\n\n\n\n\n\n\n\n\n\n3.3.2 Estéticas\nEs el diseño básico del gráfico (Aesthetics).\nMapeo de variables a propiedades visuales como color, forma o tamaño, definidas con aes().\nA diferencia del lienzo en blanco, ya contamos con un diseño. En este caso, hemos indicado al R que el eje X será la variable Pobreza.\n\ndata |&gt; \n  ggplot()+\n  aes(x=Pobreza, y=gastoedu)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEn ggplot2, las capas de un gráfico se van adicionando secuencialmente utilizando el operador +.\n\n\n\n\n3.3.3 Geometrías (Geoms)\nSon representaciones gráficas de los datos, como puntos, líneas o barras (geom_point(), geom_line(), geom_bar(), etc.).\nEn nuestro ejemplo, podemos agregar la geometría de puntos para hacer un scatterplot o diagrama de dispersión:\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  geom_point()\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn el paquete {ggplot2} existen 30 geometrías disponibles. Puedes ver el detalle de estos en la documentación del paquete.\n\n\nEsta estructura de capas hace que ggplot2 sea extremadamente útil para explorar y presentar datos de manera efectiva, permitiendo a los usuarios desde principiantes hasta expertos crear visualizaciones de datos complejas y personalizadas con relativa facilidad.\n\n\n3.3.4 Facetas\nPermite descomponer un gráfico en subgráficos, también llamadas cuadrículas o facetas, según una variable cualitativa.\nSirve para comparar grupos, separándolos y así facilitando la identificación de diferencias significativas entre estos.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  geom_point() + \n  facet_wrap(~Continent)\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nEn este punto podemos agregar también un color distinto a cada continente:\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  geom_point() + \n  facet_wrap(~Continent)+\n  aes(color=Continent)\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n3.3.5 Estadísticas\nPermite adicionar geometrías basados estadísticos específicos calculados a partir de los datos de insumo.\nPor ejemplo, se puede colocar la media de una variable numérica.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  aes(color=Continent)+\n  geom_point()+\n  geom_hline(aes(yintercept = mean(gastoedu)), linetype = \"dotdash\", color = \"blue\")\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n3.3.6 Coordenadas\nDefine el sistema de coordenadas usado para el gráfico. Puede ser cartesiano (por default), polar, etc.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  aes(color=Continent)+\n  geom_point()+\n  scale_x_log10()\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nTambién podemos editar a nivel de las etiquetas que es súmamente importante para que el lector identifique a qué se refiere cada eje.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  aes(color=Continent)+\n  geom_point(size=2)+\n  labs(title=\"Gráfico de dispersión de gasto en educación y el Índice de Corrupción\", \n      subtitle=\"Año 2018\", \n      caption=\"Fuente: FMI\\nElaboración Propia\", \n      x=\"Índice de Corrupción\",\n      y=\"Gasto público en educación (% PBI)\")\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n3.3.7 Temas\nControla los aspectos no relacionados con los datos del gráfico, como la fuente, colores de fondo, líneas de cuadrícula, márgenes, etc.\nFunciones: theme_gray(), theme_bw(), theme_classic()\nSe puede crear un tema para que se adapte a la imagen institucional de una organización o al tipo de diseño de un documento específico.\nSe modifican temas tales como el color del fondo, los ejes, tamaño del gráfico, grilla, posición de los nombres, entre otros.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=gastoedu)+\n  aes(color=Continent)+\n  geom_point(size=2)+\n  labs(title=\"Gráfico de dispersión de gasto en educación y el Índice de Corrupción\", \n      subtitle=\"Año 2018\", \n      caption=\"Fuente: FMI\\nElaboración Propia\", \n      x=\"Índice de Corrupción\",\n      y=\"Gasto público en educación (% PBI)\")+\n  theme_classic()\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nTambién te sugiero ver este video de soporte",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#para-variables-categóricas",
    "href": "c3_visualizacion.html#para-variables-categóricas",
    "title": "3  Visualización de datos",
    "section": "3.4 Para variables categóricas",
    "text": "3.4 Para variables categóricas\nDependiendo del tipo de variables que se analizan, las técnicas y herramientas de visualización varían. A continuación, se describen las aproximaciones recomendadas para visualizar datos, diferenciando entre variables categóricas y numéricas.\n\n3.4.1 Gráfico de barras simple\nEn un gráfico de barras vertical,las categorías se representan en el eje horizontal y la frecuencia o cantidad en el eje vertical.\nEl gráfico de barras es una herramienta útil para comparar la frecuencia o cantidad de diferentes categorías o variables en un conjunto de datos.\nUtilizamos la función geom_bar(). El resultado es que la función ha CONTADO la frecuencia de cada categoría de DemocracyIndexCat\n\ndata |&gt;                # Data\n  ggplot() +           # Iniciamos la construcción del gráfico con ggplot \n  aes(x = Democracy_Index_cat) + # Establecemos la variable como el eje x\n  geom_bar()           # Creamos un gráfico de barras basado en el conteo de 'continent'\n\n\n\n\n\n\n\n\nEn algunas ocasiones ya contamos con el conteo realizado y sólo deseamos el gráfico. Para ello utilizamos el ARGUMENTO stat=“identity”.\nUn caso como el siguiente:\n\ndata |&gt;  \n  count(Democracy_Index_cat)\n\n# A tibble: 5 × 2\n  Democracy_Index_cat     n\n  &lt;chr&gt;               &lt;int&gt;\n1 Authoritarian          24\n2 Flawed democracy       32\n3 Full democracy         11\n4 Hybrid regime          23\n5 &lt;NA&gt;                    5\n\n\nEn estos casos utilizamos la función:\n\ndata |&gt;  \n  count(Democracy_Index_cat) |&gt; \n  ggplot() +           \n  aes(y = n, x=Democracy_Index_cat) + #En este caso le he tenido que especificar tanto x como y!\n  geom_bar(stat=\"identity\")          \n\n\n\n\n\n\n\n\nAgregando etiquetas de los datos y nombres de los ejes:\n\ndata |&gt;  \n  count(Democracy_Index_cat) |&gt; \n  ggplot() +           \n  aes(y = n, x=Democracy_Index_cat) + #En este caso le he tenido que especificar tanto x como y!\n  geom_bar(stat=\"identity\")+\n  geom_text(aes(label=n, vjust=-1, size=3))+\n  labs(x=\"Tipo de régimen\", y=\"Frecuencia\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nAunque los gráficos de pie son ampliamente reconocidos y frecuentemente utilizados para mostrar proporciones de un todo, en la práctica suelen ser menos efectivos que los gráficos de barras. Esto se debe a que los gráficos de barras ofrecen una comparación más clara y precisa entre categorías, facilitando la interpretación de las diferencias en magnitud.\n\n\n\n\n3.4.2 Gráfico de barras acumulada\nUn gráfico de barras apiladas (acumuladas) es una forma de visualizar datos categóricos donde cada barra representa una categoría y las subcategorías se apilan una encima de otra dentro de la misma barra. Esto permite ver tanto el total de cada categoría como la contribución de cada subcategoría al total.\n\ndata |&gt; \n  drop_na(Continent, Democracy_Index_cat) |&gt; \n  ggplot()+\n  aes(x = Continent, fill = Democracy_Index_cat)+\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nPodemos personalizar el gráfico un poco más. Cómo lo presentaría el propio equipo de The Economist?\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.4.1\n\ndata |&gt; \n  drop_na(Continent, Democracy_Index_cat) |&gt; \n  ggplot()+\n  aes(x = Continent, fill = Democracy_Index_cat)+\n  geom_bar(position = \"fill\")+\n  geom_text(aes(label = scales::percent(after_stat(count)/tapply(after_stat(count), after_stat(x), sum)[after_stat(x)], accuracy = 0.1)), size=3,\n            stat = \"count\",\n            position = position_fill(vjust = 0.5)) +\n  labs(title=\"Tipo de régimen político según continente\", \n      x=\"\",\n      y=\"\",\n      fill = \"Categoría\",\n        caption=\"Fuente: Economist Intelligence Unit\\nElaborado por Christian Chiroque\") + \ntheme_economist() + scale_fill_economist() + theme(legend.text = element_text(size = 8))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSobre geom_text()\n\n\n\n\n\nDentro de geom_text, estamos utilizando la función aes() para definir la estética del texto, específicamente la etiqueta (label) que se mostrará en cada segmento de la barra apilada. El cálculo dentro de aes(label = …) utiliza scales::percent() para convertir un valor en un formato de porcentaje con una precisión de un decimal, lo cual se especifica con accuracy = 0.1. El valor dentro de scales::percent() se calcula como el conteo de observaciones (after_stat(count)) dividido por el total de observaciones en la categoría correspondiente del eje x, obtenido mediante tapply(after_stat(count), after_stat(x), sum)[after_stat(x)], donde after_stat(count) accede al conteo generado por ggplot2 y after_stat(x) accede a las categorías del eje x. Este cálculo da como resultado la proporción de cada subcategoría dentro de su categoría principal. La función geom_text() también incluye stat = “count”, lo que indica que las etiquetas se basan en los conteos de las barras, y position = position_fill(vjust = 0.5), que posiciona las etiquetas en el centro de cada segmento apilado de la barra (vjust = 0.5 centra verticalmente las etiquetas en cada subcategoría). Finalmente, size = 3 ajusta el tamaño del texto de las etiquetas, haciéndolo más pequeño para mejorar la legibilidad del gráfico.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#para-variables-numéricas",
    "href": "c3_visualizacion.html#para-variables-numéricas",
    "title": "3  Visualización de datos",
    "section": "3.5 Para variables numéricas",
    "text": "3.5 Para variables numéricas\n\n3.5.1 Boxplot\n\nEs utilizado para representar la distribución de un conjunto de datos numéricos a través de sus cuartiles.\nEl gráfico consiste en una caja que representa el rango intercuartil (IQR),es decir, la diferencia entre el tercer cuartil (Q3) y el primer cuartil(Q1).\nDentro de la caja,se dibuja una línea que representa la mediana.\nLos bigotes,que se extienden desde la caja, indican el rango de los datos que se encuentran dentro de un cierto múltiplo del IQR, generalmente 1.5 veces el IQR.\n\ndata |&gt; \n  ggplot() + \n  aes(y = PBIPC) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nLos valores que están por encima o por debajo de los bigotes se representan como puntos o asteriscos, que se conocen como valores atípicos.\nEl boxplot es útil para identificar valores atípicos y para comparar la distribución de varios conjuntos de datos en un solo gráfico. También permite visualizar la simetría o asimetría de la distribución y la presencia de sesgo.\nPuedes probar este video sugerido:\n\nTambién puedes solicitar boxplot por grupos:\n\ndata |&gt; \n  ggplot() + \n  aes(y = PBIPC, colour=Continent) + \n  geom_boxplot() + \n  labs(title=\"PBI per cápita ($) según continente\",\n      caption=\"Gapminder Dataset\") + \n  theme_stata() + scale_color_stata()\n\n\n\n\n\n\n\n\n¿qué nos dice este gráfico?\n\n\n3.5.2 Histograma\nUn histograma es un tipo de gráfico utilizado en estadísticas para representar la distribución de un conjunto de datos numéricos mediante barras. Cada barra en un histograma representa la frecuencia (número de veces que ocurren) de datos dentro de un intervalo o “bin” específico.\nLos bins dividen el espectro completo de los datos en series de intervalos consecutivos, y son todos de igual tamaño. La altura de cada barra muestra cuántos datos caen dentro de cada intervalo.\n\ndata |&gt; \n  ggplot() + \n  aes(x=PBIPC) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nLos histogramas permiten observar cómo se distribuyen los datos, revelando si están equilibradamente repartidos o inclinados hacia un extremo. Una distribución es simétrica cuando las mitades a ambos lados de la media son imágenes espejo.\nSi está sesgada hacia la derecha, significa que hay una acumulación de datos hacia el lado izquierdo del gráfico, con una cola que se extiende hacia la derecha. Como en el caso del gráfico de líneas arriba.\nPor otro lado, un sesgo hacia la izquierda indica una concentración de datos hacia la derecha, con una cola que se alarga hacia la izquierda. Los histogramas también muestran si los datos se agrupan en torno a varios valores centrales, evidenciado por la presencia de varios picos o “modas”.\nAsí como nuestros gráficos anteriores, podemos personalizar mucho más nuestro gráfico:\n\ndata |&gt; \n  ggplot() + \n  aes(x=PBIPC) + \n  geom_histogram()+\n  geom_vline(xintercept = mean(data$PBIPC), color = \"red\")+\n  geom_vline(xintercept = median(data$PBIPC), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Gráfico de línea\nEl gráfico de líneas es una herramienta de visualización de datos que conecta puntos de datos individuales con líneas, mostrando tendencias o cambios en una variable numérica a lo largo del tiempo o de otra variable numérica. Sirve principalmente para visualizar la evolución de una o varias cantidades, permitiendo identificar patrones, tendencias, picos, y caídas en los datos a lo largo de un período o rango específico.\n\nlibrary(readxl)\nCPI&lt;-read_xlsx(\"data/CPI.xlsx\")\n\nCómo evolucionó Perú y Bolivia en el CPI score desde el 2017?.\n\nCPI |&gt; \n  filter(country==\"Peru\"|country==\"Bolivia\" |country==\"Italy\") |&gt; \n  ggplot() +\n  aes(x=year, y=cpi_score, color=country)+\n  geom_line()+\n  geom_point()+\n  ylim(0, 80)+\n  geom_text(aes(label=round(cpi_score, 1)), \n            vjust=-0.5,                   \n            hjust=1.2) \n\n\n\n\n\n\n\n\n\n\n3.5.4 Gráfico de dispersión\nYa lo habíamos visto arriba pero lo definimos también. Un gráfico de dispersión, también conocido como diagrama de dispersión o scatter plot, es un tipo de gráfico que utiliza coordenadas cartesianas para mostrar la relación entre dos variables numéricas. Cada punto en el gráfico representa un par de valores (x, y), donde la posición en el eje horizontal (x) corresponde a una variable y la posición en el eje vertical (y) corresponde a la otra variable.\n\ndata |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=Democracy_Index)+\n  aes(color=Continent)+\n  geom_point(size=2)+\n  labs(title=\"Gráfico de dispersión de Índice de Democracia y el Índice de Corrupción\", \n      subtitle=\"Año 2018\", \n      caption=\"Fuente: The Economist y Transparency International\\nElaboración Propia\", \n      x=\"Índice de Corrupción\",\n      y=\"Democracy Index\")+\n  theme_economist() + scale_colour_economist()+\n  theme(plot.title = element_text(size = 12),       \n        plot.subtitle = element_text(size = 10),    \n        legend.title = element_text(size = 10),    \n        legend.text = element_text(size = 8))\n\nWarning: Removed 6 rows containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c3_visualizacion.html#ggplot-interactivo",
    "href": "c3_visualizacion.html#ggplot-interactivo",
    "title": "3  Visualización de datos",
    "section": "3.6 Ggplot interactivo",
    "text": "3.6 Ggplot interactivo\nggplotly es una función del paquete plotly en R que permite convertir gráficos estáticos creados con ggplot2 en gráficos interactivos. Esta conversión enriquece la experiencia del usuario al permitir la interacción con los gráficos, como hacer zoom, desplazar, y mostrar información adicional mediante tooltips (cuadros emergentes).\nEsto es especialmente útil para explorar datos de manera más dinámica y obtener insights adicionales que no son posibles con gráficos estáticos.\n\nlibrary(plotly)\n\nVeamos nuevamente el gráfico de dispersión anterior:\n\ngrafico_plano&lt;-data |&gt; \n  ggplot()+\n  aes(x=CPI_Index, y=Democracy_Index, label=Pais)+\n  aes(color=Continent)+\n  geom_point(size=2)+\n  labs(title=\"Gráfico de dispersión de Índice de Democracia y el Índice de Corrupción\", \n      subtitle=\"Año 2018\", \n      caption=\"Fuente: The Economist y Transparency International\\nElaboración Propia\", \n      x=\"Índice de Corrupción\",\n      y=\"Democracy Index\")+\n  theme_economist() + scale_colour_economist() +\n  theme(plot.title = element_text(size = 12),       \n        plot.subtitle = element_text(size = 10),    \n        legend.title = element_text(size = 10),    \n        legend.text = element_text(size = 8))\n\nLo convertimos en interactivo:\n\ngrafico_interactivo&lt;-ggplotly(grafico_plano)\ngrafico_interactivo\n\n\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos gráficos interactivos funcionan mejor en archivos HTML, documentos R Markdown (con output: html_document), y Jupyter Notebooks, permitiendo zoom, tooltips, y paneo, ideales para presentaciones web y dashboards interactivos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html",
    "href": "c4_transformacion.html",
    "title": "4  Transformación de tablas y otros",
    "section": "",
    "text": "4.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#objetivos-de-la-sesión",
    "href": "c4_transformacion.html#objetivos-de-la-sesión",
    "title": "4  Transformación de tablas y otros",
    "section": "",
    "text": "En esta clase exploraremos algunas funciones para manipulación de tablas tanto de dplyr como del paquete tidyr.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#base-de-datos",
    "href": "c4_transformacion.html#base-de-datos",
    "title": "4  Transformación de tablas y otros",
    "section": "4.2 Base de datos",
    "text": "4.2 Base de datos\nAbrimos nuestra base de datos:\n\nlibrary(tidyverse)\n\n\nlibrary(readxl)\ndataf&lt;-read_xlsx(\"data/resultados_sv_2021.xlsx\")\n\nExploramos:\n\nnames(dataf)\n\n[1] \"cod_dep_reniec\"  \"cod_prov_reniec\" \"REGION\"          \"PROVINCIA\"      \n[5] \"cod_prov_inei\"   \"castillo\"        \"keiko\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#configuración-de-variables",
    "href": "c4_transformacion.html#configuración-de-variables",
    "title": "4  Transformación de tablas y otros",
    "section": "4.3 Configuración de variables",
    "text": "4.3 Configuración de variables\nVemos que la variable castillo y keiko se encuentran como character.\n\nglimpse(dataf)\n\nRows: 196\nColumns: 7\n$ cod_dep_reniec  &lt;chr&gt; \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"02\", \"02\", …\n$ cod_prov_reniec &lt;chr&gt; \"0101\", \"0102\", \"0103\", \"0104\", \"0105\", \"0106\", \"0107\"…\n$ REGION          &lt;chr&gt; \"AMAZONAS\", \"AMAZONAS\", \"AMAZONAS\", \"AMAZONAS\", \"AMAZO…\n$ PROVINCIA       &lt;chr&gt; \"CHACHAPOYAS\", \"BAGUA\", \"BONGARA\", \"LUYA\", \"RODRIGUEZ …\n$ cod_prov_inei   &lt;chr&gt; \"0101\", \"0102\", \"0103\", \"0105\", \"0106\", \"0104\", \"0107\"…\n$ castillo        &lt;chr&gt; \"55.15\", \"65.544\", \"57.451\", \"56.686\", \"53.112\", \"92.1…\n$ keiko           &lt;chr&gt; \"36.763\", \"28.8\", \"35.737\", \"37.088\", \"38.672\", \"4.59\"…\n\n\nEste caso podemos coercionar estos vectores para que sean numéricos utilizando la función as.numeric():\n\nas.numeric(dataf$castillo) #En este caso SÓLO ESTAMOS VISUALIZANDO la variable convertida a numérica\n\n  [1] 55.150 65.544 57.451 56.686 53.112 92.161 61.776 58.977 58.935 61.926\n [11] 61.942 38.930 56.688 43.794 75.240 76.341 67.635 70.180 69.701 44.603\n [21] 69.261 61.586 81.195 70.801 70.047 43.059 47.049 69.789 75.732 78.336\n [31] 79.447 84.269 81.510 79.215 59.327 84.377 54.287 41.808 71.520 76.045\n [41] 67.556 79.215 78.386 84.310 76.028 73.638 69.137 77.637 84.040 87.936\n [51] 77.697 70.904 73.889 54.418 50.932 75.934 57.308 68.935 81.736 84.258\n [61] 66.050 68.532 68.640 74.852 67.928 74.899 66.851 88.161 83.051 82.460\n [71] 91.364 87.578 91.693 87.341  0.000 86.659 88.315 85.377 82.743 84.016\n [81] 82.842 83.765 64.469 80.839 64.721  0.000 59.452 62.896 75.751 77.521\n [91] 75.799 50.644 76.736 57.070 80.801 82.187 86.792 44.609 43.780 45.341\n[101] 46.986 50.010 56.084 51.852 47.903 63.186 47.891 63.272 52.641 49.755\n[111] 64.179 31.193 56.630 45.825 47.916 39.507 52.822 51.573 36.770 42.964\n[121] 51.974 29.757 51.421 37.399 45.856 40.274 32.261 42.030 49.562 42.818\n[131] 43.395 50.248 57.267 40.582 41.221 52.420 39.994 59.098 54.044 39.226\n[141] 52.899 25.861  0.000  0.000 65.978  0.000 58.509 74.556 80.779 58.032\n[151] 71.090 81.404 34.417 33.274 66.050 68.005 39.255 38.913 26.121 39.899\n[161] 37.140 80.898 92.249 84.934 90.296 90.997 87.792 89.261 85.170 79.809\n[171] 87.709 89.659 91.065 90.279 52.660 53.294 49.506 51.882 56.660 43.038\n[181] 60.099 62.580 49.943 55.339 67.644 82.742 79.789 88.103 34.070 26.044\n[191] 25.527 30.353 40.919 65.022 41.578  0.000\n\n\n\ndataf$castillo&lt;-as.numeric(dataf$castillo) #Con el signo de asignación estamos CREANDO (o sobreescribiendo) la variable.\n\nLo comprobamos solicitando su clase:\n\nclass(dataf$castillo)\n\n[1] \"numeric\"\n\n\nSi queremos hacer muchas coerciones de forma simultánea podemos utilizar la función lapply(), la cual es una de las funciones de la familia “apply” en R, diseñada para aplicar una función a los elementos de una lista o a los componentes de un objeto.\n\ndataf[,6:7]&lt;-lapply(dataf[,6:7], as.numeric)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#etiquetas-a-las-variables",
    "href": "c4_transformacion.html#etiquetas-a-las-variables",
    "title": "4  Transformación de tablas y otros",
    "section": "4.4 Etiquetas a las variables",
    "text": "4.4 Etiquetas a las variables\nEl etiquetado de columnas en R sirve para asignar descripciones más significativas o detalladas a las variables de un conjunto de datos. Las etiquetas mejoran la legibilidad y comprensión del código y los resultados, y son particularmente valiosas en análisis estadísticos, informes, y visualizaciones donde el contexto y la claridad son cruciales.\nPor ejemplo, label(dataf$castillo) &lt;- “Votación por Castillo” asigna la etiqueta “Votación por Castillo” a la columna castillo del dataframe dataf. Este método es útil para aclarar el significado de las variables, especialmente cuando los nombres de las columnas son breves o técnicos.\n\nlibrary(Hmisc)\nlabel(dataf$castillo)&lt;-\"Votación por Castillo\"\nlabel(dataf$keiko)&lt;-\"Votación por Keiko\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#repasa-case_when",
    "href": "c4_transformacion.html#repasa-case_when",
    "title": "4  Transformación de tablas y otros",
    "section": "4.5 Repasa case_when()",
    "text": "4.5 Repasa case_when()\nRecuerda que la función case_when() del paquete dplyr sirve para recodificar datos y crear nuevas variables o modificar variables existentes basándose en múltiples condiciones.\nPermite evaluar varias condiciones utilizando una sintaxis similar a una instrucción “if-else”. Esta función es particularmente útil cuando necesitamos recodificar una variable en varias categorías o cuando tenemos múltiples condiciones a evaluar.\nPodemos realizar:\n\ndataf&lt;-dataf  |&gt;   # Data\n  select(3,4,6,7)  |&gt;  # Selecciono estas columnas \n    mutate(nivel_respaldo_castillo=  #Creo una nueva variable que se llamará \"nivel_respado_castillo\"...\n        case_when(castillo&lt;30~\"Bajo\",  # donde se le asigna la etiqueta \"Bajo\" si es menor a 30...\n                  castillo&lt;60~\"Medio\", # la etiqueta \"Medio\" si es menor a 60 y...\n                  TRUE~\"Alto\")) # la etiqueta \"Alto\" a todas las demás que no cumplen con lo anterior. \n\nComo en este caso la variable es ordinal, hay que especificarle ello al R:\n\ndataf$nivel_respaldo_castillo&lt;-factor(dataf$nivel_respaldo_castillo, \n                                       levels = c(\"Bajo\", \"Medio\", \"Alto\"), ordered = T)\n\nlabel(dataf$nivel_respaldo_castillo) = \"Nivel de respaldo a Pedro Castillo\"\n\n\n\n\n\n\n\nNota\n\n\n\nPodríamos generar otra variable que indique quién ganó en esa provincia. Cómo sería?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#tablas-de-resumen-con-gtsummary",
    "href": "c4_transformacion.html#tablas-de-resumen-con-gtsummary",
    "title": "4  Transformación de tablas y otros",
    "section": "4.6 Tablas de resumen con gtsummary",
    "text": "4.6 Tablas de resumen con gtsummary\n\nEl paquete gtsummary en R (2019) es una herramienta diseñada para simplificar y agilizar la creación de tablas resumen estadísticas y de datos. Es conocido por ser útil especialmente en el contexto de la investigación biomédica y la epidemiología, pero aplica para todos los rubros.\nEste paquete permite a los usuarios generar rápidamente tablas bien formateadas que resumen características básicas de un conjunto de datos, como medias, medianas, intervalos, y frecuencias. También es capaz de realizar pruebas estadísticas y presentar sus resultados de manera clara y concisa. La gran ventaja de gtsummary es que convierte procesos que normalmente requerirían varias líneas de código y un conocimiento profundo de estadísticas en tareas mucho más sencillas y directas, facilitando la comunicación de resultados estadísticos y la elaboración de informes y publicaciones científicas.\n\n4.6.1 tbl_summary() para resumir\nSe utiliza para crear tablas resumen detalladas y bien formateadas de las características de las variables en un conjunto de datos.\nPara esta función se le pueden incluir los siguientes “tipos” de variables: continuous, categorical, dichotomous, y continuous2.\n\nLas variables continuous se refieren a variables numéricas que se resumen en una sola fila, típicamente con estadísticas como la media y la desviación estándar.\nLas variables categorical son aquellas con un número limitado de categorías o grupos, y se resumen mostrando conteos y porcentajes para cada categoría.\nLas variables dichotomous son un caso especial de variables categóricas con solo dos categorías, como ‘Sí’ o ‘No’.\nFinalmente, continuous2 es similar a continuous, pero ofrece un resumen más detallado al desglosar las estadísticas en dos o más filas, permitiendo una representación más completa de los datos numéricos.\n\nAntes de hacer nuestras tablas, hay que decirle al R que el lenguaje que estamos usando es español y que nuestro separador de decimales es el “.”:\n\nlibrary(gtsummary)\n\n#StandWithUkraine\n\ntheme_gtsummary_language(\n  language = \"es\",\n  decimal.mark = \".\"\n)\n\nSetting theme `language: es`\n\n\nPrimero hagamos una prueba con nuestra data que tiene dos variables continuous y una categorical. Podemos notar que para la primera sólo lo resume en una línea (mediana y rango intercuartílico), mientras que para la segunda te muestra la frecuencia y porcentaje de cada categoría.\n\ndataf |&gt; \n  select(castillo, keiko, nivel_respaldo_castillo) |&gt; \n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nN = 1961\n\n\n\n\nVotación por Castillo\n63 (48, 79)\n\n\nVotación por Keiko\n29 (14, 43)\n\n\nNivel de respaldo a Pedro Castillo\n\n\n\n\n    Bajo\n11 (5.6%)\n\n\n    Medio\n81 (41%)\n\n\n    Alto\n104 (53%)\n\n\n\n1 Mediana (RIQ); n (%)\n\n\n\n\n\n\n\n\nPodemos modificar para que ahora nos muestre la Media(Desviación estándar) para todas las numéricas:\n\nlibrary(gtsummary)\ndataf |&gt; \n  select(castillo, keiko, nivel_respaldo_castillo) |&gt; \n  tbl_summary(statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nN = 1961\n\n\n\n\nVotación por Castillo\n61 (21)\n\n\nVotación por Keiko\n30 (18)\n\n\nNivel de respaldo a Pedro Castillo\n\n\n\n\n    Bajo\n11 (5.6%)\n\n\n    Medio\n81 (41%)\n\n\n    Alto\n104 (53%)\n\n\n\n1 Media (DE); n (%)\n\n\n\n\n\n\n\n\nAhora generamos una variable dicotómica dummy que indique si es que en la provincia ganó Castillo:\n\ndataf&lt;-dataf  |&gt;   # Data\n      mutate(castillo_gano=  \n        case_when(castillo&gt;keiko~1,  \n                  TRUE~0))\nlabel(dataf$castillo_gano)=\"Ganó Pedro Castillo\"\n\nY solicitamos nuevamente la tabla resumen. Vemos que al ser dicotómica lo presenta en una sola línea:\n\ndataf |&gt; \n  select(castillo, keiko, nivel_respaldo_castillo, castillo_gano) |&gt; \n  tbl_summary(statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nN = 1961\n\n\n\n\nVotación por Castillo\n61 (21)\n\n\nVotación por Keiko\n30 (18)\n\n\nNivel de respaldo a Pedro Castillo\n\n\n\n\n    Bajo\n11 (5.6%)\n\n\n    Medio\n81 (41%)\n\n\n    Alto\n104 (53%)\n\n\nGanó Pedro Castillo\n149 (76%)\n\n\n\n1 Media (DE); n (%)\n\n\n\n\n\n\n\n\nY qué pasaría si queremos convertir una de nuestra continuous en continuous2? Es decir, solicitarle que nos de mayor información?\n\ndataf |&gt; \n  select(castillo, keiko, nivel_respaldo_castillo, castillo_gano) |&gt; \n  tbl_summary(\n    type = keiko ~ \"continuous2\",\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",\n                    all_continuous2() ~ c(\"{mean} ({sd})\", \"{min}, {max}\")))\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nN = 1961\n\n\n\n\nVotación por Castillo\n61 (21)\n\n\nVotación por Keiko\n\n\n\n\n    Media (DE)\n30 (18)\n\n\n    Rango\n0, 69\n\n\nNivel de respaldo a Pedro Castillo\n\n\n\n\n    Bajo\n11 (5.6%)\n\n\n    Medio\n81 (41%)\n\n\n    Alto\n104 (53%)\n\n\nGanó Pedro Castillo\n149 (76%)\n\n\n\n1 Media (DE); n (%)\n\n\n\n\n\n\n\n\n\n\n4.6.2 Personalización de encabezados\nFinalmente, podemos personalizar aún más la tabla con los comandos modify_header y modify_caption para editar los encabezados en nuestro idioma.\n\ndataf |&gt; \n  select(castillo, keiko, nivel_respaldo_castillo, castillo_gano) |&gt; \n  tbl_summary(\n    type = keiko ~ \"continuous2\",\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",\n                    all_continuous2() ~ c(\"{mean} ({sd})\", \"{min}, {max}\"))) |&gt; \n  modify_header(label = \"**Variable de interés**\") |&gt; \n  modify_caption(\"**Tabla resumen con `gtsummary`**\") \n\n\n\n\n\nTabla resumen con gtsummary\n\n\n\n\n\n\nVariable de interés\nN = 1961\n\n\n\n\nVotación por Castillo\n61 (21)\n\n\nVotación por Keiko\n\n\n\n\n    Media (DE)\n30 (18)\n\n\n    Rango\n0, 69\n\n\nNivel de respaldo a Pedro Castillo\n\n\n\n\n    Bajo\n11 (5.6%)\n\n\n    Medio\n81 (41%)\n\n\n    Alto\n104 (53%)\n\n\nGanó Pedro Castillo\n149 (76%)\n\n\n\n1 Media (DE); n (%)\n\n\n\n\n\n\n\n\n\n\n4.6.3 Videos recomendados\nTe recomiendo ver estos dos tutoriales sobre gtsummary, ambos muy buenos. Ten en cuenta que en estos casos ya entran más a detalle sobre la generación de tablas de resumen con este paquete:\nhttps://www.youtube.com/watch?v=6QTrzd2Wxrs\nhttps://www.youtube.com/watch?v=tANo9E1SYJE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#videos-recomendados",
    "href": "c4_transformacion.html#videos-recomendados",
    "title": "4  Transformación de tablas y otros",
    "section": "4.7 Videos recomendados",
    "text": "4.7 Videos recomendados\nTe recomiendo ver estos dos tutoriales sobre gtsummary, ambos muy buenos. Ten en cuenta que en estos casos ya entran más a detalle sobre la generación de tablas de resumen con este paquete:\nhttps://www.youtube.com/watch?v=6QTrzd2Wxrs\nhttps://www.youtube.com/watch?v=tANo9E1SYJE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c4_transformacion.html#mutating-joins",
    "href": "c4_transformacion.html#mutating-joins",
    "title": "4  Transformación de tablas y otros",
    "section": "4.7 Mutating Joins",
    "text": "4.7 Mutating Joins\n\nLos mutating joins son una serie de funciones en R, particularmente en el paquete dplyr, que permiten combinar dos tablas basadas en columnas clave compartidas. Estas funciones no solo agregan filas de una tabla a otra, sino que también modifican las columnas de la tabla original al añadir información de la tabla complementaria. Entre los mutating joins más comunes se encuentran left_join(), right_join(), inner_join() y full_join(), cada uno diseñado para combinar tablas de diferentes maneras según las relaciones entre las claves de las tablas.\n\n4.7.1 Tablas de ejemplo\nGeneramos dos tablas a modo de ejemplo:\n\n# Crear la primera tabla de ejemplo\ntabla1 &lt;- data.frame(\n  ID = 1:10,\n  Nombre = c('Ana', 'Carlos', 'Elena', 'Luis', 'María', 'Pedro', 'Rosa', 'José', 'Clara', 'Marta'),\n  Edad = c(23, 34, 45, 28, 39, 41, 30, 38, 33, 29)\n)\n\n# Crear la segunda tabla de ejemplo\ntabla2 &lt;- data.frame(\n  ID = c(1, 3, 5, 7, 9, 11, 12, 13, 14, 15),\n  Puntaje = c(88, 92, 75, 85, 90, 67, 72, 83, 94, 77)\n)\n\nLas visualizamos:\n\ntabla1\n\n   ID Nombre Edad\n1   1    Ana   23\n2   2 Carlos   34\n3   3  Elena   45\n4   4   Luis   28\n5   5  María   39\n6   6  Pedro   41\n7   7   Rosa   30\n8   8   José   38\n9   9  Clara   33\n10 10  Marta   29\n\n\nLa tabla 2:\n\ntabla2\n\n   ID Puntaje\n1   1      88\n2   3      92\n3   5      75\n4   7      85\n5   9      90\n6  11      67\n7  12      72\n8  13      83\n9  14      94\n10 15      77\n\n\n\n\n4.7.2 Variable KEY\nLa variable key es la columna o conjunto de columnas que existen en ambas tablas y que se usan para encontrar las filas correspondientes en cada tabla. Es esencialmente el criterio de emparejamiento. Por ejemplo, si tienes una tabla con datos demográficos de personas (tabla1) y otra con sus puntajes en un examen (tabla2), la clave podría ser una columna como ID que identifique de manera única a cada persona en ambas tablas.\n\n\n\n\n\n\nTip\n\n\n\nLa variable key (o clave) se precisará el argumento by dentro de las funciones left_join(), right_join(), inner_join() y full_join().\n\n\n\n\n4.7.3 left_join()\nleft_join() toma todas las filas de tabla1 (la tabla de la izquierda) y añade las columnas de tabla2 donde haya coincidencias en la columna ID. Si no hay coincidencia en tabla2, las nuevas columnas tendrán valores NA\n\nleft_join_result &lt;- left_join(tabla1, tabla2, by = \"ID\")\nleft_join_result\n\n   ID Nombre Edad Puntaje\n1   1    Ana   23      88\n2   2 Carlos   34      NA\n3   3  Elena   45      92\n4   4   Luis   28      NA\n5   5  María   39      75\n6   6  Pedro   41      NA\n7   7   Rosa   30      85\n8   8   José   38      NA\n9   9  Clara   33      90\n10 10  Marta   29      NA\n\n\n\n\n4.7.4 right_join()\nright_join() toma todas las filas de tabla2 (la tabla de la derecha) y añade las columnas de tabla1 donde haya coincidencias en la columna ID. Si no hay coincidencia en tabla1, las nuevas columnas tendrán valores NA.\n\nright_join_result &lt;- right_join(tabla1, tabla2, by = \"ID\")\nright_join_result\n\n   ID Nombre Edad Puntaje\n1   1    Ana   23      88\n2   3  Elena   45      92\n3   5  María   39      75\n4   7   Rosa   30      85\n5   9  Clara   33      90\n6  11   &lt;NA&gt;   NA      67\n7  12   &lt;NA&gt;   NA      72\n8  13   &lt;NA&gt;   NA      83\n9  14   &lt;NA&gt;   NA      94\n10 15   &lt;NA&gt;   NA      77\n\n\n\n\n4.7.5 inner_join()\nDevuelve solo las filas donde haya coincidencias en la columna ID en ambas tablas. Las filas sin coincidencia son eliminadas del resultado.\n\ninner_join_result &lt;- inner_join(tabla1, tabla2, by = \"ID\")\ninner_join_result\n\n  ID Nombre Edad Puntaje\n1  1    Ana   23      88\n2  3  Elena   45      92\n3  5  María   39      75\n4  7   Rosa   30      85\n5  9  Clara   33      90\n\n\n\n\n4.7.6 full_join()\nDevuelve todas las filas de ambas tablas. Si hay coincidencia en la columna ID, las filas se combinan; si no hay coincidencia, se incluyen las filas con valores NA en las columnas donde no hubo coincidencia.\n\nfull_join_result &lt;- full_join(tabla1, tabla2, by = \"ID\")\nfull_join_result\n\n   ID Nombre Edad Puntaje\n1   1    Ana   23      88\n2   2 Carlos   34      NA\n3   3  Elena   45      92\n4   4   Luis   28      NA\n5   5  María   39      75\n6   6  Pedro   41      NA\n7   7   Rosa   30      85\n8   8   José   38      NA\n9   9  Clara   33      90\n10 10  Marta   29      NA\n11 11   &lt;NA&gt;   NA      67\n12 12   &lt;NA&gt;   NA      72\n13 13   &lt;NA&gt;   NA      83\n14 14   &lt;NA&gt;   NA      94\n15 15   &lt;NA&gt;   NA      77\n\n\n\n\n4.7.7 Lectura recomendada\nTe sugiero leer el capítulo “Joins” de R for Data Science en este link.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transformación de tablas y otros</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html",
    "href": "c2_1-dashboards.html",
    "title": "5  Dashboards con Quarto",
    "section": "",
    "text": "5.1 ¿Qué es un dashboard?\nUn dashboard (o tablero de control) es una herramienta visual que concentra en una sola pantalla los indicadores, métricas y datos más importantes de un proceso, área o proyecto. Su objetivo es ofrecer una visión clara, resumida y rápida del estado de la información, permitiendo tomar decisiones informadas sin necesidad de revisar reportes extensos.\nCaracterísticas principales",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#objetivos-de-la-sesión",
    "href": "c2_1-dashboards.html#objetivos-de-la-sesión",
    "title": "5  Dashboards con Quarto",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de reconocer las características principales del programa R, incluyendo sus elementos básicos y los fundamentos para el análisis estadístico. Además, sabrá implementar los procedimientos básicos necesarios para iniciar cualquier análisis estadístico en R.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#presentación",
    "href": "c2_1-dashboards.html#presentación",
    "title": "5  Dashboards con Quarto",
    "section": "Presentación",
    "text": "Presentación",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#sobre-r",
    "href": "c2_1-dashboards.html#sobre-r",
    "title": "5  Dashboards con Quarto",
    "section": "5.1 Sobre R",
    "text": "5.1 Sobre R\n\n5.1.1 Consideraciones básicas\nR es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos.\nR es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un número, una base de datos o un modelo estadístico.\nCada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él.\nImagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística.\n\n\n5.1.2 Dónde escribir mi código: Script\nExisten varias formas de escribir código en el R. Para ello tenemos algunas opciones simples, como el Script y otras un poco más elaboradas como Quarto.\nPara fines de esta primera clase vamos a utilizar el script, el cual es un documento de texto que tiene la peculiaridad que puede ser leídos por el programa como un manual de código. De esa forma, nosotros podemos colocar en el script los códigos de nuestro análisis, ordenarlos, comentarlos y reproducirlos en el R Studio automáticamente.\nEn suma, podemos redactar nuestros script, compartirlos con otros investigadores y ejecutarlos.\n\nComo comentario: Cuando nosotros colocamos el símbolo # al iniciar una oración, el Script lo va a identificar como un comentario del programador, como un texto que no va a ser ejecutado como código. Esto es importante porque nos permite ir comentando, por ejemplo, lo que estamos redactando en el documento. Ej: “Este código sirve para abrir un archivo”, “Aquí estoy haciendo un análisis de regresión”, entre otros.\nComo código: Cuando escribimos directamente en el documento el programa lo va a entender como código o funciones. Esto es importante tenerlo en cuenta para evitar notificaciones de Error.\n\nTe recomiendo ver el siguiente video para que puedas aprender más sobre el Script, pero también sobre las otras opciones que el R te puede ofrecer y que usaremos más adelante.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#elementos-básicos",
    "href": "c2_1-dashboards.html#elementos-básicos",
    "title": "5  Dashboards con Quarto",
    "section": "5.2 Elementos básicos",
    "text": "5.2 Elementos básicos\n\n5.2.1 Objetos\nVamos a examinar la clase de algunos de los elementos más básicos en R.\nUn objeto puede ser un número. En este caso el objeto es de tipo numeric.\n\n5\n\n[1] 5\n\n\nO también podría ser un nombre de un país. En este caso el objeto es de tipo character. Vas a notar que se trata de un caractér porque vas a visualizar el resultado entre comillas.\n\n\"Perú\"\n\n[1] \"Perú\"\n\n\nLos objetos también pueden almacenarse en la memoria del programa con ciertos “nombres”. Por ejemplo:\n\nyear&lt;-2024\nyear\n\n[1] 2024\n\n\n\ncountry&lt;-\"Perú\"\ncountry\n\n[1] \"Perú\"\n\n\nUno puede asignar un nombre a un objeto en el R con la flecha de asignación (&lt;-)\n\n\n\n\n\n\nNota\n\n\n\nHay otro tipo de objetos conocidos como factores que los estudiaremos líneas más abajo!.\n\n\n\n\n5.2.2 Vectores\n\nUn vector es una colección de uno o más datos del mismo tipo.\nTipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico.\n\nEjemplo: Vamos a crear tres vectores: uno numérico, uno de caracter.\n\nvector_numerico &lt;- c(1, 2, 3, 4, 5)\nvector_numerico\n\n[1] 1 2 3 4 5\n\n\n\nvector_caracter &lt;- c(\"arbol\", \"casa\", \"persona\")\nvector_caracter\n\n[1] \"arbol\"   \"casa\"    \"persona\"\n\n\n\n\n5.2.3 Funciones\nUna función es como una máquina a la que le das un insumo, o input para que realice un procedimiento específico. Luego de realizar el procedimiento, la máquina te da un resultado que le vamos a llamar output.\nPor ejemplo, podemos utilizar la función sqrt() para obtener la raíz cuadrada de un número. En este caso aplicamos una función sobre un sólo número.\n\nsqrt(16)\n\n[1] 4\n\n\nPero también podemos aplicar una función sobre un vector. Por ejemplo, podemos solicitar la función sum() para obtener la suma de todos los elementos de un vector numérico:\n\nsum(vector_numerico)\n\n[1] 15\n\n\nTambién podemos utilizar la función class() para corroborar que la clase del vector que tenemos.\n\nclass(vector_numerico)\n\n[1] \"numeric\"\n\nclass(vector_caracter)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nSiempre te vas a dar cuenta que estás frente a una función porque usualmente está seguida de paréntesis en el cual se colocan los argumentos.\n\n\n\n\n5.2.4 Dataframes\nLos data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener vectores de diferentes tipos.\nEs la estructura más usada para ciencia de datos y la que vamos a ver de forma más recurrente en el curso.\nLo más importante que debes recordar es que las filas en un dataframe representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables.\nPor ejemplo, tenemos la siguiente información sobre ciertos departamentos del Perú y sus niveles de pobreza:\n\ndepartamentos&lt;-c(\"Huancavelica\", \"Ayacucho\", \"Pasco\")\npobreza&lt;-c(47.7, 46.4, 44.8)\nmi_df&lt;-data.frame(departamentos, pobreza)\nmi_df\n\n  departamentos pobreza\n1  Huancavelica    47.7\n2      Ayacucho    46.4\n3         Pasco    44.8\n\n\nUna forma de examinar rápidamente un dataframe es utilizando la función str():\n\nstr(mi_df)\n\n'data.frame':   3 obs. of  2 variables:\n $ departamentos: chr  \"Huancavelica\" \"Ayacucho\" \"Pasco\"\n $ pobreza      : num  47.7 46.4 44.8\n\n\nEl output de esta función te indica las dimensiones del dataframe (número de observaciones y número de variables), así como los nombres de las variables, el tipo y algunos valores de muestra.\nOtra función básica para explorar es names(), la cual te arroja exclusivamente los nombres de las variables del dataframe:\n\nnames(mi_df)\n\n[1] \"departamentos\" \"pobreza\"      \n\n\n\n\n\n\n\n\nImportante\n\n\n\nUn error frecuente es no identificar correctamente las unidades de análisis con las que estamos trabajando. Al abrir un conjunto de datos, lo primero que debes preguntarte es: ¿A qué se refiere esta información? ¿A personas, países, instituciones?\n\n\n\n\n5.2.5 Índices\n\nUsar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos.\nUn índice en R representa una posición.\nCuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella.\n\nEjemplos:\n\nSeleccionar la columna 2:\n\n\nmi_df [,2]\n\n[1] 47.7 46.4 44.8\n\n\nPara seleccionar una columna, también podemos usar el símbolo de $.\n\nmi_df$pobreza\n\n[1] 47.7 46.4 44.8\n\n\nNormalmente lo usamos cuando queremos aplicar una función a sólo una columna. Como por ejemplo:\n\nmean(mi_df$pobreza)\n\n[1] 46.3\n\n\n\nSeleccionar sólo el caso (fila) 2:\n\n\nmi_df [2,]\n\n  departamentos pobreza\n2      Ayacucho    46.4\n\n\n\nSeleccionar el elemento que se encuentra en la fila 2 y la columna 2:\n\n\nmi_df [2,2]\n\n[1] 46.4\n\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que en los [,] primero se mencionan las filas y luego las columnas.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#procedimientos-básicos",
    "href": "c2_1-dashboards.html#procedimientos-básicos",
    "title": "5  Dashboards con Quarto",
    "section": "5.3 Procedimientos básicos",
    "text": "5.3 Procedimientos básicos\nHasta aquí hemos aprendido los elementos básicos del R, ahora procederemos a analizar los procedimientos más cotidianos que realizaremos en un proceso de análisis de datos estadísticos.\n\n5.3.1 Apertura de paquetes\nLíneas arriba te había comentado que existían funciones que podías aplicar sobre objetos en el R. Dabas un input y la función te arrojaba un determinado resultado.\nAhora bien, lo más interesante del R es que existen diferentes “conjuntos de funciones” para tareas específicas y que uno puede instalar y utilizar en tu proceso de análisis.\nPara instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete).\nHagamos la prueba con el paquete rio, el cual es un paquete creado para importar/exportar archivos de diversos tipos.\nPrimero lo vamos a instalar. No te olvides que cuando instalas un paquete el nombre del mismo va entre comillas:\n\n#install.packages(\"rio\")\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que la instalación de paquetes se realiza sólo una vez. Esto quiere decir que si instalas hoy el paquete “rio” ya no será necesario que realices esta operación nuevamente.\n\n\nLuego de instalarlo lo debemos abrir para utilizar las funciones que están dentro de él.\n\nlibrary(rio)\n\n\n\n5.3.2 Apertura de archivos\nLo más común es que se te va a entregar un archivo para que lo puedas abrir en el R.\nPara ello, una primera forma sencilla de abrir un archivo es haciendo uso de la función import del paquete rio:\n\ndata&lt;-import(\"data/regiones.xlsx\") \n#Dentro del () colocas la ubicación del archivo.\n\nUna vez que abrimos una data y corroboramos que está en nuestro Environment podemos explorarla.\nViendo un encabezado de las primeras filas:\n\nhead(data)\n\n     region macroregion poblacion pobreza nivel_pobreza  agua desague\n1  Amazonas     Oriente    379384    47.3             3 51.84   36.69\n2    Ancash       Norte   1083519    23.5             2 71.56   56.38\n3  Apurímac         Sur    405759    42.8             3 56.33   36.12\n4  Arequipa         Sur   1382730     9.1             1 72.47   65.85\n5  Ayacucho         Sur    616176    51.9             3 66.99   45.35\n6 Cajamarca       Norte   1341012    52.9             3 52.89   32.48\n  electrificacion acceso_internet telefonia_movil pc_tablet hospitales\n1           73.67            4.45           69.39     11.02          8\n2           85.20           18.33           79.60     25.00         23\n3           80.43            8.93           71.21     14.74          8\n4           89.98           32.88           91.28     40.52         24\n5           80.94           10.42           77.65     17.84         11\n6           80.68            9.29           74.66     14.10         25\n\n\nAnalizando su estructura:\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : chr  \"Oriente\" \"Norte\" \"Sur\" \"Sur\" ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : num  3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...\n\n\n\nnames(data)\n\n [1] \"region\"          \"macroregion\"     \"poblacion\"       \"pobreza\"        \n [5] \"nivel_pobreza\"   \"agua\"            \"desague\"         \"electrificacion\"\n [9] \"acceso_internet\" \"telefonia_movil\" \"pc_tablet\"       \"hospitales\"     \n\n\n\n\n5.3.3 Identificación teórica de la variable\n\nAntes de seguir en el análisis debemos corroborar los tipos de variables con los que estamos trabajando a nivel teórico.\nEn una data real, esto normalmente lo encontramos en el Cuestionario o Diccionario de Variables. Según la teoría estadistica podemos tener dos grandes opciones.\n\n5.3.3.1 Numéricas\nLas variables numéricas son aquellas que representan cantidades medidas o contadas, y pueden ser de tipo entero o decimal. Permiten realizar operaciones matemáticas y son fundamentales en el análisis estadístico y cuantitativo.\nSe clasifican en continuas y discretas, basándose en los valores que pueden tomar.\nLas variables discretas representan información que se puede contar en unidades enteras, como el número de hospitales en nuestra base de datos.\nPor otro lado, las variables continuas pueden tomar cualquier valor dentro de un rango, incluyendo decimales. En nuestra base de datos contamos con variables como * como la altura o el peso pobreza, agua, entre otros. Esto significa que pueden medir con precisión infinita dentro de su escala, adaptándose a una variedad más amplia de datos y mediciones.\n\n\n5.3.3.2 Categóricas\nUna variable categórica clasifica las observaciones en grupos o categorías que no tienen un orden matemático inherente. Se dividen en nominales y ordinales.\nLas variables nominales representan categorías sin un orden específico entre ellas, como colores, nombres de países o géneros. En nuestra data una variable nominal sería macroregion.\nEn cambio, las variables ordinales sí poseen un orden o jerarquía entre las categorías, aunque la distancia entre estas no es necesariamente uniforme; por ejemplo, niveles de educación o calificaciones de satisfacción. Continuando con el ejemplo, la variable ordinal nivel_pobreza clasifica en categorías donde el 1 corresponde a “Bajo”, el 2 a “Medio” y el 3 a “Alto”.\n\n\n\n5.3.4 Configuración de las variable en R\nAhora veamos qué tenemos en nuestra data.\nVeamos las siguientes tres variables: poblacion (numérica), macroregión (nominal) y nivel de pobreza (ordinal).\nDichas variables qué tipo de objeto son actualmente en el R?\n\n5.3.4.1 Numeric\n\nclass(data$poblacion)\n\n[1] \"numeric\"\n\n\nPara el caso de población cuenta con la configuración adecuada pues es numeric.\nTen en cuenta que para el caso de una variable numérica discreta como hospitales la configuración adecuada también es numeric.\n\n\n5.3.4.2 Factors\nPara el caso de las variables categóricas, para poder trabajar con estas en el R debemos convertirlas a un tipo especial de objeto denominado factor.\nBásicamente, un factor es una variable que tiene grupos, los cuales pueden estar ordenados o no ordenados.\nFACTORES NO ORDENADOS\nPara el caso de la variable nominal macroregión que inicialmente está mal configurada (pues tiene el tipo character).\n\nclass(data$macroregion)\n\n[1] \"character\"\n\n\nvamos a convertirla en un factor no ordenado.\n\ndata$macroregion&lt;-factor(data$macroregion)\n\n\n\n\n\n\n\nTip\n\n\n\nHemos empleado la función factor() y el operador de asignación porque estamos modificando una parte de nuestro conjunto de datos. En otras palabras, estamos actualizando la variable macroregión con su configuración correcta.\n\n\nPodemos corroborar el tipo final pidiendo otra vez la función str():\n\nstr(data$macroregion)\n\n Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n\n\nEn este caso nos menciona que ahora la variable macroregion es un factor con cuatro niveles (Centro, Norte, Sur, Oriente).\n\n\n\n\n\n\nImportante\n\n\n\nSi bien aquí vemos la palabra “niveles” esto no quiere decir que para R esos niveles tengan un orden, sino más bien que son categorías diferentes.\n\n\nFACTORES ORDENADOS\nAhora bien, el caso del nivel de pobreza es diferente, ya que, aunque también es un factor, sus niveles presentan un orden de magnitud específico.\nEn este caso, además de convertirla en factor, es necesario especificar el orden de los niveles, indicando que efectivamente se trata de una secuencia ordenada.\n\ndata$nivel_pobreza&lt;-factor(data$nivel_pobreza,\n                          levels = c(1,2,3),\n                          ordered = TRUE)\n\nMediante la función str(), confirmamos que nuestra variable nivel_pobreza se ha convertido efectivamente en un factor ordenado con tres niveles, donde 1 es menor que 2 y, a su vez, 2 es menor que 3.\n\nstr(data$nivel_pobreza)\n\n Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n\n\n\n\n\n\n\n\nImportante\n\n\n\nAunque para nosotros los niveles parecen ser números (1, 2 o 3), para R no lo son. Esto significa que no es posible realizar operaciones matemáticas con ellos.\n\n\nAhora con esta configuración ya estamos listos para el siguiente paso: manipular tablas y calculas estadísticos descriptivos.\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#ficha-resumen-cheat-sheet",
    "href": "c2_1-dashboards.html#ficha-resumen-cheat-sheet",
    "title": "5  Dashboards con Quarto",
    "section": "5.4 Ficha resumen (Cheat Sheet)",
    "text": "5.4 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#qué-es-un-dashboard",
    "href": "c2_1-dashboards.html#qué-es-un-dashboard",
    "title": "5  Dashboards con Quarto",
    "section": "",
    "text": "Visualización: utiliza gráficos, tablas, mapas o indicadores numéricos fáciles de interpretar.\nSíntesis: muestra lo más relevante; no todo el detalle, sino lo esencial para el seguimiento.\nInteractividad: en muchos casos permite filtrar, explorar y profundizar en la información.\nActualización: suele estar conectado a bases de datos o fuentes en tiempo real o periódicas.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#tipos-de-dashboard",
    "href": "c2_1-dashboards.html#tipos-de-dashboard",
    "title": "5  Dashboards con Quarto",
    "section": "5.2 Tipos de dashboard",
    "text": "5.2 Tipos de dashboard\n📊 Dashboard estático\nQué es: muestra información fija en un momento determinado. Se construye a partir de un dataset cerrado y no cambia a menos que se vuelva a generar manualmente.\nCaracterísticas:\n\nNo se actualiza automáticamente.\nSirve como un reporte visual (ej. un PDF o una presentación con gráficos).\nIdeal para análisis que no requieren cambios frecuentes.\n\n⚡ Dashboard dinámico\nQué es: está conectado a una o varias fuentes de datos y se actualiza en tiempo real o cada cierto intervalo. Permite la interacción del usuario.\nCaracterísticas:\nSe actualiza automáticamente (en tiempo real o con actualizaciones programadas).\nEl usuario puede filtrar, explorar y profundizar en los datos.\nÚtil para la toma de decisiones en vivo.\nEjemplo: un dashboard en R Shiny, Qlik Sense o Power BI donde puedes filtrar por fechas, regiones o productos y los gráficos se ajustan al instante.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "c2_1-dashboards.html#pasos-para-crear-un-dashboard",
    "href": "c2_1-dashboards.html#pasos-para-crear-un-dashboard",
    "title": "5  Dashboards con Quarto",
    "section": "5.3 Pasos para crear un dashboard",
    "text": "5.3 Pasos para crear un dashboard\nLos dashboards en Quarto permiten organizar y visualizar información en un formato web accesible y bien estructurado. A diferencia de los dashboards dinámicos (como los que se construyen en Shiny), un dashboard estático en Quarto no se conecta en tiempo real a los datos ni permite interacción compleja, pero es ideal para presentar reportes reproducibles, con navegación clara y un diseño profesional.\n\n5.3.1 1. Crear el entorno de trabajo\nPrimero debemos crear un proyecto Quarto. Esto es recomendable porque:\n\nMantiene todos los archivos organizados en una misma carpeta.\nFacilita la reutilización de recursos (imágenes, hojas de estilo, logos).\nPermite renderizar el dashboard sin conflictos de rutas de archivos.\n\n\n\n5.3.2 2. Configurar el tipo de documento\nEn el archivo principal (.qmd), editamos el encabezado YAML para indicar que deseamos un dashboard como formato de salida:\ntitle: “Mi Dashboard”\nformat: dashboard\nEsto asegura que Quarto renderice el documento con la estructura y componentes propios de un panel de control.\n\n\n5.3.3 3. Barra de navegación\nAl ejecutar el documento, Quarto genera automáticamente una barra de navegación en blanco. Esta barra es clave porque permite al usuario desplazarse entre secciones o páginas del dashboard.\n\nPuede incluir enlaces, menús desplegables o íconos.\nMejora la experiencia del usuario, al facilitar el acceso a diferentes áreas de datos o visualizaciones.\n\n\n\n5.3.4 4. Agregar un logo institucional\nEs posible personalizar el encabezado del dashboard incluyendo un logo. Para ello:\n\nColoca la imagen en la carpeta del proyecto.\nHaz referencia a ella desde el YAML.\n\nEsto le da identidad institucional al documento y profesionaliza la presentación.\n\n\n5.3.5 5. Crear páginas (módulos)\nCada página corresponde a una sección temática dentro del dashboard. Se definen con un encabezado de nivel 1:\n# Nombre de la página\nEsto permite organizar el panel en módulos independientes (ej. “Análisis descriptivo”, “Modelos predictivos”, “Conclusiones”), facilitando la navegación.\n\n\n5.3.6 6. Diseñar el layout\nEl layout es la disposición de los elementos dentro de cada página (gráficos, tablas, texto). Una buena organización asegura que la información sea clara y fácil de interpretar.\n\nDentro de una página, los encabezados de nivel 2 (##) crean filas.\nEn cada fila puedes ubicar contenido en columnas, tarjetas u otros elementos.\n\n💡 Sugerencia: antes de escribir código, piensa cómo deseas que se organice la información.\n\n\n5.3.7 Sidebar (barra lateral)\nEl sidebar es una barra que aparece en uno de los lados del dashboard:\n\nEn un dashboard estático, se utiliza principalmente para mostrar información adicional o enlaces.\nEn un dashboard dinámico (Shiny), el sidebar sirve como área de interacción: filtros, selectores o controles que modifican el contenido en tiempo real.\n\n\n\n5.3.8 Agregar contenido con tarjetas (cards)\nLas cards son bloques visuales que permiten resumir información de manera compacta.\n\nPueden contener cifras clave, gráficos pequeños o texto breve.\nDestacan datos importantes de un vistazo.\nMejoran la legibilidad al estructurar la información en secciones bien delimitadas.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos dashboards en Quarto son estáticos por defecto. Si necesitas interactividad avanzada (inputs, filtros, actualización dinámica de gráficos), debes combinar Quarto con Shiny o integrar elementos HTML/JS.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboards con Quarto</span>"
    ]
  },
  {
    "objectID": "2_c1_dashboards.html",
    "href": "2_c1_dashboards.html",
    "title": "5  Quarto dashboards",
    "section": "",
    "text": "5.1 ¿Qué es un dashboard?\nUn dashboard (o tablero de control) es una herramienta visual que concentra en una sola pantalla los indicadores, métricas y datos más importantes de un proceso, área o proyecto. Su objetivo es ofrecer una visión clara, resumida y rápida del estado de la información, permitiendo tomar decisiones informadas sin necesidad de revisar reportes extensos.\nCaracterísticas principales",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Quarto dashboards</span>"
    ]
  },
  {
    "objectID": "2_c1_dashboards.html#qué-es-un-dashboard",
    "href": "2_c1_dashboards.html#qué-es-un-dashboard",
    "title": "5  Quarto dashboards",
    "section": "",
    "text": "Visualización: utiliza gráficos, tablas, mapas o indicadores numéricos fáciles de interpretar.\nSíntesis: muestra lo más relevante; no todo el detalle, sino lo esencial para el seguimiento.\nInteractividad: en muchos casos permite filtrar, explorar y profundizar en la información.\nActualización: suele estar conectado a bases de datos o fuentes en tiempo real o periódicas.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Quarto dashboards</span>"
    ]
  },
  {
    "objectID": "2_c1_dashboards.html#tipos-de-dashboard",
    "href": "2_c1_dashboards.html#tipos-de-dashboard",
    "title": "5  Quarto dashboards",
    "section": "5.2 Tipos de dashboard",
    "text": "5.2 Tipos de dashboard\n📊 Dashboard estático\nQué es: muestra información fija en un momento determinado. Se construye a partir de un dataset cerrado y no cambia a menos que se vuelva a generar manualmente.\nCaracterísticas:\n\nNo se actualiza automáticamente.\nSirve como un reporte visual (ej. un PDF o una presentación con gráficos).\nIdeal para análisis que no requieren cambios frecuentes.\n\n⚡ Dashboard dinámico\nQué es: está conectado a una o varias fuentes de datos y se actualiza en tiempo real o cada cierto intervalo. Permite la interacción del usuario.\nCaracterísticas:\nSe actualiza automáticamente (en tiempo real o con actualizaciones programadas).\nEl usuario puede filtrar, explorar y profundizar en los datos.\nÚtil para la toma de decisiones en vivo.\nEjemplo: un dashboard en R Shiny, Qlik Sense o Power BI donde puedes filtrar por fechas, regiones o productos y los gráficos se ajustan al instante.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Quarto dashboards</span>"
    ]
  },
  {
    "objectID": "2_c1_dashboards.html#pasos-para-crear-un-dashboard-estático",
    "href": "2_c1_dashboards.html#pasos-para-crear-un-dashboard-estático",
    "title": "5  Quarto dashboards",
    "section": "5.3 Pasos para crear un dashboard estático",
    "text": "5.3 Pasos para crear un dashboard estático\nLos dashboards en Quarto permiten organizar y visualizar información en un formato web accesible y bien estructurado. A diferencia de los dashboards dinámicos (como los que se construyen en Shiny), un dashboard estático en Quarto no se conecta en tiempo real a los datos ni permite interacción compleja, pero es ideal para presentar reportes reproducibles, con navegación clara y un diseño profesional.\n\n5.3.1 1. Crear el entorno de trabajo\nPrimero debemos crear un proyecto Quarto. Esto es recomendable porque:\n\nMantiene todos los archivos organizados en una misma carpeta.\nFacilita la reutilización de recursos (imágenes, hojas de estilo, logos).\nPermite renderizar el dashboard sin conflictos de rutas de archivos.\n\n\n\n5.3.2 2. Configurar el tipo de documento\nEn el archivo principal (.qmd), editamos el encabezado YAML para indicar que deseamos un dashboard como formato de salida:\ntitle: “Mi Dashboard”\nformat: dashboard\nEsto asegura que Quarto renderice el documento con la estructura y componentes propios de un panel de control.\n\n\n5.3.3 3. Barra de navegación\nAl ejecutar el documento, Quarto genera automáticamente una barra de navegación en blanco. Esta barra es clave porque permite al usuario desplazarse entre secciones o páginas del dashboard.\n\nPuede incluir enlaces, menús desplegables o íconos.\nMejora la experiencia del usuario, al facilitar el acceso a diferentes áreas de datos o visualizaciones.\n\n\n\n5.3.4 4. Agregar un logo institucional\nEs posible personalizar el encabezado del dashboard incluyendo un logo. Para ello:\n\nColoca la imagen en la carpeta del proyecto.\nHaz referencia a ella desde el YAML.\n\nEsto le da identidad institucional al documento y profesionaliza la presentación.\n\n\n5.3.5 5. Crear páginas (módulos)\nCada página corresponde a una sección temática dentro del dashboard. Se definen con un encabezado de nivel 1:\n# Nombre de la página\nEsto permite organizar el panel en módulos independientes (ej. “Análisis descriptivo”, “Modelos predictivos”, “Conclusiones”), facilitando la navegación.\n\n\n5.3.6 6. Diseñar el layout\nEl layout es la disposición de los elementos dentro de cada página (gráficos, tablas, texto). Una buena organización asegura que la información sea clara y fácil de interpretar.\n\nDentro de una página, los encabezados de nivel 2 (##) crean filas.\nEn cada fila puedes ubicar contenido en columnas, tarjetas u otros elementos.\n\n💡 Sugerencia: antes de escribir código, piensa cómo deseas que se organice la información.\n\n\n5.3.7 7. Sidebar (barra lateral)\nEl sidebar es una barra que aparece en uno de los lados del dashboard:\n\nEn un dashboard estático, se utiliza principalmente para mostrar información adicional o enlaces.\nEn un dashboard dinámico (Shiny), el sidebar sirve como área de interacción: filtros, selectores o controles que modifican el contenido en tiempo real.\n\n\n\n5.3.8 8. Agregar contenido con tarjetas (cards)\nLas cards son bloques visuales que permiten resumir información de manera compacta.\n\nPueden contener cifras clave, gráficos pequeños o texto breve.\nDestacan datos importantes de un vistazo.\nMejoran la legibilidad al estructurar la información en secciones bien delimitadas.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos dashboards en Quarto son estáticos por defecto. Si necesitas interactividad avanzada (inputs, filtros, actualización dinámica de gráficos), debes combinar Quarto con Shiny o integrar elementos HTML/JS.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Quarto dashboards</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html",
    "href": "2_c2_shiny.html",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "",
    "text": "6.1 ¿Por qué Shiny?\nShiny es un paquete desarrollado por RStudio (ahora Posit) que fue lanzado en 2012 con el objetivo de acercar el poder de R a un entorno web. Antes de Shiny, quienes querían compartir resultados interactivos debían exportar los gráficos o programar en otros lenguajes (HTML, JavaScript), lo que hacía el proceso más complejo y menos accesible para usuarios de R.\nCon Shiny se introdujo un marco que permite:\nSu popularidad creció rápidamente en la comunidad de ciencia de datos y análisis aplicado, porque abrió la posibilidad de pasar de un análisis reproducible en R a una herramienta interactiva lista para la toma de decisiones o la enseñanza.\nHoy Shiny se integra fácilmente con Quarto, lo que permite combinar la estructura clara de documentos reproducibles con la interactividad de aplicaciones web.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#qué-es-un-dashboard",
    "href": "2_c2_shiny.html#qué-es-un-dashboard",
    "title": "6  Quarto dashboards",
    "section": "",
    "text": "Visualización: utiliza gráficos, tablas, mapas o indicadores numéricos fáciles de interpretar.\nSíntesis: muestra lo más relevante; no todo el detalle, sino lo esencial para el seguimiento.\nInteractividad: en muchos casos permite filtrar, explorar y profundizar en la información.\nActualización: suele estar conectado a bases de datos o fuentes en tiempo real o periódicas.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto dashboards</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#tipos-de-dashboard",
    "href": "2_c2_shiny.html#tipos-de-dashboard",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "6.2 Tipos de dashboard",
    "text": "6.2 Tipos de dashboard\n📊 Dashboard estático\nQué es: muestra información fija en un momento determinado. Se construye a partir de un dataset cerrado y no cambia a menos que se vuelva a generar manualmente.\nCaracterísticas:\n\nNo se actualiza automáticamente.\nSirve como un reporte visual (ej. un PDF o una presentación con gráficos).\nIdeal para análisis que no requieren cambios frecuentes.\n\n⚡ Dashboard dinámico\nQué es: está conectado a una o varias fuentes de datos y se actualiza en tiempo real o cada cierto intervalo. Permite la interacción del usuario.\nCaracterísticas:\nSe actualiza automáticamente (en tiempo real o con actualizaciones programadas).\nEl usuario puede filtrar, explorar y profundizar en los datos.\nÚtil para la toma de decisiones en vivo.\nEjemplo: un dashboard en R Shiny, Qlik Sense o Power BI donde puedes filtrar por fechas, regiones o productos y los gráficos se ajustan al instante.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#pasos-para-crear-un-dashboard-estático",
    "href": "2_c2_shiny.html#pasos-para-crear-un-dashboard-estático",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "6.3 Pasos para crear un dashboard estático",
    "text": "6.3 Pasos para crear un dashboard estático\nLos dashboards en Quarto permiten organizar y visualizar información en un formato web accesible y bien estructurado. A diferencia de los dashboards dinámicos (como los que se construyen en Shiny), un dashboard estático en Quarto no se conecta en tiempo real a los datos ni permite interacción compleja, pero es ideal para presentar reportes reproducibles, con navegación clara y un diseño profesional.\n\n6.3.1 1. Crear el entorno de trabajo\nPrimero debemos crear un proyecto Quarto. Esto es recomendable porque:\n\nMantiene todos los archivos organizados en una misma carpeta.\nFacilita la reutilización de recursos (imágenes, hojas de estilo, logos).\nPermite renderizar el dashboard sin conflictos de rutas de archivos.\n\n\n\n6.3.2 2. Configurar el tipo de documento\nEn el archivo principal (.qmd), editamos el encabezado YAML para indicar que deseamos un dashboard como formato de salida:\ntitle: “Mi Dashboard”\nformat: dashboard\nEsto asegura que Quarto renderice el documento con la estructura y componentes propios de un panel de control.\n\n\n6.3.3 3. Barra de navegación\nAl ejecutar el documento, Quarto genera automáticamente una barra de navegación en blanco. Esta barra es clave porque permite al usuario desplazarse entre secciones o páginas del dashboard.\n\nPuede incluir enlaces, menús desplegables o íconos.\nMejora la experiencia del usuario, al facilitar el acceso a diferentes áreas de datos o visualizaciones.\n\n\n\n6.3.4 4. Agregar un logo institucional\nEs posible personalizar el encabezado del dashboard incluyendo un logo. Para ello:\n\nColoca la imagen en la carpeta del proyecto.\nHaz referencia a ella desde el YAML.\n\nEsto le da identidad institucional al documento y profesionaliza la presentación.\n\n\n6.3.5 5. Crear páginas (módulos)\nCada página corresponde a una sección temática dentro del dashboard. Se definen con un encabezado de nivel 1:\n# Nombre de la página\nEsto permite organizar el panel en módulos independientes (ej. “Análisis descriptivo”, “Modelos predictivos”, “Conclusiones”), facilitando la navegación.\n\n\n6.3.6 6. Diseñar el layout\nEl layout es la disposición de los elementos dentro de cada página (gráficos, tablas, texto). Una buena organización asegura que la información sea clara y fácil de interpretar.\n\nDentro de una página, los encabezados de nivel 2 (##) crean filas.\nEn cada fila puedes ubicar contenido en columnas, tarjetas u otros elementos.\n\n💡 Sugerencia: antes de escribir código, piensa cómo deseas que se organice la información.\n\n\n6.3.7 7. Sidebar (barra lateral)\nEl sidebar es una barra que aparece en uno de los lados del dashboard:\n\nEn un dashboard estático, se utiliza principalmente para mostrar información adicional o enlaces.\nEn un dashboard dinámico (Shiny), el sidebar sirve como área de interacción: filtros, selectores o controles que modifican el contenido en tiempo real.\n\n\n\n6.3.8 8. Agregar contenido con tarjetas (cards)\nLas cards son bloques visuales que permiten resumir información de manera compacta.\n\nPueden contener cifras clave, gráficos pequeños o texto breve.\nDestacan datos importantes de un vistazo.\nMejoran la legibilidad al estructurar la información en secciones bien delimitadas.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos dashboards en Quarto son estáticos por defecto. Si necesitas interactividad avanzada (inputs, filtros, actualización dinámica de gráficos), debes combinar Quarto con Shiny o integrar elementos HTML/JS.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#por-qué-shiny",
    "href": "2_c2_shiny.html#por-qué-shiny",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "",
    "text": "Construir aplicaciones web directamente desde R, sin necesidad de aprender lenguajes adicionales.\nCrear interfaces interactivas donde el usuario puede manipular inputs (desplegables, sliders, botones).\nConectar esos inputs con outputs reactivos, que actualizan automáticamente gráficos, tablas o modelos estadísticos.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTe recomiendo leer el libro “Mastering Shiny”, sobre todo la parte de fundamentos, la cual también es importante al manipular shiny dashboards con Quarto!",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#estructura",
    "href": "2_c2_shiny.html#estructura",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "6.2 Estructura",
    "text": "6.2 Estructura\n\n6.2.1 Interfaz de usuario (UI)\nLa UI define cómo se ve el dashboard y cómo el usuario puede interactuar con él. Aquí decides la estructura visual:\n\nDónde estarán los menús, sliders, botones o selectores.\nCómo se organizan las páginas, columnas o secciones del panel.\nQué tipo de elementos visuales se van a mostrar: gráficos, tablas, texto, indicadores.\n\n\nEn términos sencillos, la UI es como el tablero de control de un auto: el velocímetro, los botones, las luces y palancas. El usuario no necesita ver cómo funcionan los sensores internos, solo necesita tenerlos a la vista y poder manipularlos.\n\n\n6.2.2 Server\nEl server es la parte lógica y funcional del dashboard. Aquí defines qué debe pasar cuando el usuario interactúa con la UI:\n\nSi el usuario mueve un slider, el server actualiza el gráfico en consecuencia.\nSi el usuario selecciona un filtro, el server procesa los datos para mostrar solo lo relevante.\nSi el usuario presiona un botón, el server ejecuta el cálculo o la acción indicada.\n\n\nEl server es como el motor del auto: recibe las órdenes (pisar el acelerador, girar el volante) y genera la respuesta (acelerar, girar las ruedas). El usuario no ve directamente el motor, pero sin él el tablero no tendría utilidad.\n\n\n\n\n\n\nNota\n\n\n\nLa separación entre UI y Server es fundamental para comprender cómo funciona Shiny. Aunque al inicio puede parecer una división técnica, en realidad refleja una lógica muy clara: lo que el usuario ve e interactúa (UI) está siempre respaldado por un proceso de cálculo y respuesta (Server).\n\n\n\n\n6.2.3 Relación IU - Server\nLa correspondencia entre la interfaz de usuario (UI) y el servidor (server) es fundamental en un dashboard con Shiny. Cada elemento que se crea en la UI —un gráfico, una tabla o un texto de salida— debe tener un nombre único que coincida con el definido en el server, y viceversa. Si en la UI mostramos un plotOutput(“ventas”), en el server debemos tener un renderPlot({…}) asociado a output$ventas. Esta relación uno a uno garantiza que lo que el usuario ve en pantalla esté conectado con la lógica que procesa los datos en segundo plano. Mantener esta coherencia no solo evita errores, sino que también asegura que la aplicación sea clara, ordenada y fácil de mantener o escalar.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c2_shiny.html#pasos-para-crear-un-dashboard-dinámico",
    "href": "2_c2_shiny.html#pasos-para-crear-un-dashboard-dinámico",
    "title": "6  Dashboard dinámico con Quarto y Shiny",
    "section": "6.3 Pasos para crear un dashboard dinámico",
    "text": "6.3 Pasos para crear un dashboard dinámico\nA diferencia de los dashboards estáticos, un dashboard con Quarto + Shiny permite que el usuario interactúe con los datos en tiempo real. Para organizar su construcción de manera ordenada, seguiremos cinco pasos principales:\n\n6.3.1 1. Previsualiza tu dashboard\nAntes de escribir código, es importante planificar la estructura del dashboard, al igual que hicimos en la clase pasada:\n\nDiseñar el layout: definir si nuestro dashboard tendrá una barra lateral (sidebar), cuántas páginas contendrá y cómo se organizarán las secciones (por ejemplo, columnas con gráficos a la izquierda y tablas a la derecha). Pensar en términos de navegación (qué temas tendrá cada página) y de presentación (qué elementos queremos destacar).\n\n\n\nCrear un proyecto interactivo con Quarto: esto nos asegura que todos los archivos, imágenes y recursos estén centralizados y listos para ser renderizados.\n\n\n\n\n6.3.2 2. Diseña tu dashboard\nPara nuestro ejemplo vamos a concebir un dashboard con la siguiente estructura:\n\nEntonces debemos\n\n\n\n6.3.3 2. Cargar la data\nLa carga de datos debe hacerse en un bloque especial llamado context: setup, que se ejecuta una sola vez al inicio y queda disponible para toda la aplicación.\n\nAquí importamos librerías (library(…)), cargamos bases de datos (read.csv(), readRDS(), etc.) y definimos funciones auxiliares.\nSeparar esta parte es importante porque nos ayuda a distinguir qué es preparación global (datos que no cambian) y qué será interactivo (lo que reacciona a los inputs del usuario).\n\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda colocar #| context:setup al inicio del chunk global\n\n\n\n\n6.3.4 3. Generar los input\nLos inputs en un dashboard de Shiny son elementos de la interfaz de usuario que permiten a los usuarios enviar datos o ajustar parámetros para interactuar con la aplicación. Generalmente (no siempre) van en el sidebar, pero pueden ubicarse también dentro de las páginas.\nEstos pueden incluir controles como cuadros de texto, deslizadores, botones y menús desplegables.\n https://gallery.shinyapps.io/081-widgets-gallery/\nLos inputs son esenciales para crear dashboards interactivos, ya que permiten a los usuarios personalizar la visualización de los datos y las análisis realizados por el servidor de Shiny en tiempo real.\nTipos comunes de inputs en Shiny:\n\n6.3.4.1 sliderInput():\nCrea una barra deslizante para seleccionar un valor numérico o un rango. Para generarlo se sigue la siguiente estructura:\n\nPara nuestro ejemplo vamos a generar:\n\n\n\n6.3.4.2 selectInput():\nEste widget crea un menú desplegable que permite a los usuarios elegir una única opción de una lista predefinida.\nEs útil para filtrar datos o configurar parámetros específicos dentro de la aplicación Shiny.\nTener en cuenta que en el argumento choices puedes colocar c(“opcion1”, “opcion2”) o también el nombre de una lista que hayas creado antes.\nPara generarlo se sigue la siguiente estructura:\n\nPara nuestro ejemplo vamos a generar:\n\n\n\n6.3.4.3 checkboxGroupInput():\nGenera un grupo de casillas de verificación, permitiendo a los usuarios seleccionar múltiples opciones de un conjunto. Este widget es ideal para aplicaciones que requieren selecciones múltiples y no excluyentes.\nTener en cuenta que en el argumento choices puedes colocar c(“opcion1”, “opcion2”) o también el nombre de una lista que hayas creado antes.\n\n\n\n\n\n\n\nNota\n\n\n\nCada input genera un objeto reactivo que se usará luego en el servidor para filtrar datos o actualizar gráficos.\n\n\nPara nuestro ejemplo vamos a generar:\n\n\n\n\n6.3.5 4. Generar el servidor y los outputs\nLo colocamos al final del documento. Tiene un encabezado que dice #| context: server.\nAquí vamos a colocar el código que va a generar de forma interactiva (usando los inputs) los gráficos o tablas que deseemos. Tener en cuenta que hay distintas funciones que van a renderizar outputs dependiendo de su tipo.\nEn Quarto, esta lógica se coloca en un bloque con context: server, que se ejecuta continuamente en función de los inputs.\n\nEl insumo principal del server son los objetos creados por los inputs.\nEl resultado son los outputs (gráficos, tablas, indicadores).\n\nEn nuestro caso usaremos renderPlot() y renderTable(), pero existen otras funciones:\n\nPara nosotros vamos a generar un primer plot en nuestro servidor:\n\n\n\n\n\n\n\nNota\n\n\n\nCada output tiene un nombre (plot1).\nIniciamos la construcción del output con la función pertinente (renderPlot()). En este caso vamos a generar un gráfico.\nPara que el gráfico sea interactivo, además de las consideraciones de siempre, debemos colocar los inputs creados anteriormente. Un paso inicial sencillo es configurar que la interacción sea con filter().\nSi corremos este código no se va a visibilizar nada, pues sólo se encontrará en el server.\n\n\n\n\n6.3.6 5. Crear la interfaz de usuario\nUna vez definidos los inputs (ej. en el sidebar) y generados los outputs en el server, debemos mostrar esos resultados en la interfaz.\n\nLa UI se encarga de colocar los gráficos, tablas o indicadores en el lugar correcto.\nEn Quarto dashboards, esto puede hacerse directamente con encabezados y secciones, donde insertamos los outputs de Shiny con plotOutput(), tableOutput(), etc.\nAquí tienes que tener en cuenta que, como te indiqué en el paso 2, ya tienes que tener tu dashboard diseñado. En otras palabras, debes tener claro dónde va a ir este gráfico al final.\nEn cada “apartado” del layout (columna o fila, de ser el caso) vamos a “mostrar” el output que ya ha sido creado en el server anteriormente. Ten cuidado con los nombres (mayúsculas, símbolos),ya que debe ser exacto.\n\n\nTener en cuenta que así como tenemos una función para generar outputs en server, también tiene su función correspondiente para presentar el output en el UI.\nEn nuestro caso podemos generar:\n\n\n\n\n\n\n\nNota\n\n\n\n\nPuedes colocarle un título al gráfico desde la misma tarjeta del Dashboard utilizando #| title:\nDescuida: puedes utilizar comillas simples (ALT+39, en Windows) o las comillas normales.\nA veces el lugar es muy pequeño para el tamaño del objeto. O viceversa. Si fuese el caso, tendrías que ajustar el tamaño.\n\n\n\n\n\n6.3.7 6. Despliegue del dashboard\nEl último paso es hacer que nuestro dashboard esté disponible para los usuarios. Esto se conoce como despliegue.\n\nExisten varias formas de hacerlo (servidores locales, RStudio Connect, Docker, etc.), pero en este curso utilizaremos shinyapps.io:\n\nEs un servicio en la nube ofrecido por Posit.\nPermite publicar aplicaciones Shiny directamente desde RStudio o Quarto.\nSolo necesitas una cuenta gratuita y ejecutar rsconnect::deployApp() para que tu dashboard esté disponible en línea.\n\n\nEn resumen, el despliegue es el paso que convierte tu proyecto en una aplicación accesible desde cualquier navegador.\n\n\n\n\n\n\nNota\n\n\n\nShinyapps.io, al igual que otras aplicaciones, es un servicio de pago.\nSin embargo, tiene una versión libre que te permite:\n\nCargar tu app a la nube.\nContar con un máximo de 5 aplicaciones.\nTe permite un uso máximo de 25 horas por mes.\n\nTener en cuenta que tienes que instalar el paquete “rsconnect” previamente.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Dashboard dinámico con Quarto y Shiny</span>"
    ]
  },
  {
    "objectID": "2_c3_rl.html",
    "href": "2_c3_rl.html",
    "title": "7  ML Supervisado: Regresión lineal",
    "section": "",
    "text": "7.1 Métodos Supervisados\nUn método supervisado es un tipo de técnica en machine learning en la que el modelo aprende a partir de ejemplos en los que ya conocemos la respuesta correcta. Es decir, trabajamos con un conjunto de datos que incluye tanto las variables de entrada (lo que usamos para predecir) como una variable de salida o etiqueta (lo que queremos predecir).\nEl aprendizaje se llama “supervisado” porque el modelo tiene un “supervisor”: los datos con la respuesta ya conocida. Así, el modelo ajusta sus parámetros comparando sus predicciones con las respuestas reales y corrigiendo sus errores. Una vez entrenado, podemos darle nuevos datos (sin respuesta) y el modelo intentará predecir el valor de la salida.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ML Supervisado: Regresión lineal</span>"
    ]
  },
  {
    "objectID": "2_c3_rl.html#métodos-supervisados",
    "href": "2_c3_rl.html#métodos-supervisados",
    "title": "7  ML Supervisado: Regresión lineal",
    "section": "",
    "text": "Nota\n\n\n\n¡NUEVO TÉRMINO!\nUn parámetro es un valor numérico que forma parte del modelo matemático o estadístico y que determina cómo se comporta ese modelo. Los parámetros no los escogemos “a mano”, sino que el modelo los aprende de los datos.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ML Supervisado: Regresión lineal</span>"
    ]
  },
  {
    "objectID": "2_c3_rl.html#regresión-lineal-simple",
    "href": "2_c3_rl.html#regresión-lineal-simple",
    "title": "7  ML Supervisado: Regresión lineal",
    "section": "7.3 Regresión Lineal Simple",
    "text": "7.3 Regresión Lineal Simple\n\n7.3.1 Recordar la ecuación de la recta\nDebemos acordarnos algunos elementos básicos que aprendimos desde la escuela:\n\\[\ny = \\beta_0 + \\beta_1x\n\\]\nDonde:\ny es la variable dependiente que se quiere predecir o estimar.\nx es la variable independiente que se utiliza para predecir y.\nβ₀ es la intersección de la línea y.\nβ₁ es la pendiente de la línea (indica cuánto varía Y por cada unidad de X).\nTener en cuenta que si:\n\nSi β₁ es positivo, Y aumenta cuando X aumenta.Es una relación directa / positiva.\nSi β₁ es negativo, Y aumenta cuando X disminuye. Es una relación inversa / negativa.\nSi β₁ es cero.Y no cambia cuando X varía. No existe relación entre las variables.\n\n\n\n7.3.2 Definición\nLa regresión lineal es uno de los modelos más simples y fundamentales dentro del aprendizaje supervisado. Su objetivo es predecir un valor numérico y continua a partir de una o varias variables de entrada. Se basa en la idea de que existe una relación (aproximadamente lineal) entre esas variables explicativas y la variable que queremos predecir.\nPara ello lo que hace es ajustar una línea recta (o un hiperplano, si hay varias variables) que mejor resuma la relación entre las variables de entrada (predictoras) y la variable de salida (respuesta).\n\n\n\n7.3.3 Midiendo los errores: función de costo\nLa función de costo es una fórmula matemática que mide qué tan bien (o mal) el modelo se ajusta a los datos.\nEn regresión lineal, una de las más utilizadas es la Raiz del Error Cuadrático Medio (RMSE, por sus siglas en inglés).\nDefinición:\nEl RMSE mide la magnitud promedio del error en las predicciones de un modelo, penalizando más los errores grandes y expresándose en las mismas unidades de la variable de salida.\n¿Qué significa?\n\nCada vez que el modelo predice un valor, podemos compararlo con el valor real.\nLa función de costo resume todos esos errores en un solo número.\nEse número nos indica la “calidad” del modelo: cuanto más pequeño sea, mejor está ajustada la recta a los datos.\nEl RMSE es útil porque se expresa en las mismas unidades de la variable de salida, lo que facilita su interpretación.\n\n\\[\nJ(\\beta) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\big(y_i - \\hat{y}_i\\big)^2}\n\\]\nEjemplo:\nSupongamos que queremos predecir la estatura de tres personas (en cm).\n\nValores reales: 170, 180, 190\nPredicciones: 172, 177, 189\n\nErrores:\n\n170 - 172 = -2\n180 - 177 = 3\n190 - 189 = 1\n\nCálculo:\n\\[\nRMSE = \\sqrt{\\frac{(-2)^2 + (3)^2 + (1)^2}{3}} = \\sqrt{\\tfrac{14}{3}} \\approx 2.16\n\\]\nEl modelo se equivoca en promedio 2.16 centímetros.\n\n\n7.3.4 Explicación vs Predicción\nEn el campo del análisis de datos y del machine learning suele aparecer una tensión entre dos objetivos distintos: explicar fenómenos o predecir resultados futuros.\nExplicación\nEl objetivo principal es entender las relaciones entre las variables.\nSe busca interpretar los parámetros de un modelo: por ejemplo, cómo influye la educación en los ingresos, o qué efecto tiene una política pública en la reducción de la pobreza.\nLa prioridad no es tanto acertar en nuevas observaciones, sino tener coeficientes confiables y significativos que respalden hipótesis teóricas.\nSe preocupa mucho por los supuestos estadísticos, la validez de las inferencias, la significancia y la causalidad.\nEjemplo: un economista que estima un modelo para probar si la inflación depende del precio de los metales.\n\n\n\n\n\n\n\nNota\n\n\n\nUna analogía al propósito de la explicación.\nEl interés está en saber si la obra refleja fielmente la realidad, es decir, si los datos o el modelo “explican” lo que realmente ocurrió. La pintura sirve como ejemplo de representación: ¿es una descripción precisa de lo que había en la escena?\n\n\nPredicción\nEl objetivo es obtener el mayor nivel posible de acierto en datos nuevos.\nImporta más el desempeño predictivo que la interpretación de los parámetros.\nPor ello que, en este ámbito, los modelos tienen licencia para ser “cajas negras” (random forests, redes neuronales) si eso mejora la precisión.\nSe aceptan técnicas como regularización, ensambles o validación cruzada, que priorizan generalización más que interpretación.\nEjemplo: un banco que quiere predecir si un cliente dejará de pagar un crédito, sin importar tanto cuáles variables explican el fenómeno.\n\n\n\n\n\n\n\nNota\n\n\n\nUna analogía al propósito de la predicción\nA partir del cuadro, podemos reconstruir una parte que falta (¿podemos “llenar” el trozo ausente basándonos en lo que sí vemos?)\n\n\nEn estadística clásica y ciencias sociales, la tendencia ha sido hacia la explicación: probar teorías y entender causalidad.\nEn machine learning aplicado la tendencia es hacia la predicción: lograr resultados prácticos aunque el modelo no sea interpretable.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ML Supervisado: Regresión lineal</span>"
    ]
  },
  {
    "objectID": "2_c3_rl.html#una-regresión-paso-a-paso",
    "href": "2_c3_rl.html#una-regresión-paso-a-paso",
    "title": "7  ML Supervisado: Regresión lineal",
    "section": "7.4 Una regresión paso a paso",
    "text": "7.4 Una regresión paso a paso\nEn esta sección aprenderemos, paso a paso, cómo construir un modelo de machine learning utilizando regresión lineal. Veremos desde la preparación de los datos y la definición del modelo hasta su entrenamiento, evaluación y visualización de resultados, todo dentro del flujo de trabajo de tidymodels en R.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.9     ✔ rsample      1.3.1\n✔ dials        1.4.1     ✔ tune         1.3.0\n✔ infer        1.0.9     ✔ workflows    1.3.0\n✔ modeldata    1.5.1     ✔ workflowsets 1.1.1\n✔ parsnip      1.3.3     ✔ yardstick    1.3.2\n✔ recipes      1.3.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\ndata &lt;- read_xlsx(\"data/AML_2.xlsx\")\n\nMira nuestra data, hemos identificado que tenemos ciertos países en los cuales NO TENEMOS la medida de aml_index, es decir, tenemos un NA.\n\naml_faltante &lt;- data |&gt; \n  select(pais, aml_index, pobreza) |&gt; \n  filter(is.na(aml_index))\n\n\naml_faltante\n\n# A tibble: 16 × 3\n   pais                     aml_index pobreza\n   &lt;chr&gt;                        &lt;dbl&gt;   &lt;dbl&gt;\n 1 Afghanistan                     NA    54.5\n 2 Argentina                       NA    25.7\n 3 Belize                          NA    41  \n 4 Brazil                          NA     4.2\n 5 Burundi                         NA    64.6\n 6 Central African Republic        NA    62  \n 7 Comoros                         NA    44.8\n 8 Djibouti                        NA    23  \n 9 El Salvador                     NA    32.7\n10 Eritrea                         NA    50  \n11 Guyana                          NA    35  \n12 India                           NA    21.9\n13 Lesotho                         NA    57  \n14 Nepal                           NA    25.2\n15 Papua New Guinea                NA    37  \n16 Rwanda                          NA    39.1\n\n\nQueremos predecir su AML_index con la variable pobreza. Por eso vamos a utilizar la data completa en la que sí está la variable aml_index:\n\ndata&lt;- data |&gt; \n        filter(!is.na(aml_index))\n\n\n7.4.1 Paso 1: Análisis Exploratorio de Datos (EDA)\nEn este punto, utilizaremos los hallazgos detectados en las últimas dos clases.\n\nsummary(data$aml_index)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.000   4.605   5.160   5.261   5.835   8.140 \n\n\n\nsummary(data$pobreza)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.60   14.35   22.20   25.77   31.75   72.30 \n\n\n\n\n7.4.2 Paso 1: Splitear la data\nDividir los datos en training y testing es un paso fundamental en machine learning. La idea es entrenar el modelo con una parte de la información y reservar otra parte, nunca vista por el modelo, para evaluar su capacidad de generalizar. Esto evita el sesgo de pensar que un modelo es “bueno” solo porque se ajusta bien a los datos con los que fue entrenado.\n¿Por qué se hace el split?\n🔹 Entrenamiento: el modelo aprende los patrones usando solo la porción de training.\n🔹 Evaluación: el conjunto de test sirve para medir el poder predictivo en datos nuevos.\n🔹 Prevención de sobreajuste (overfitting): si el modelo se ajusta demasiado a training, su desempeño en test revelará esa debilidad.\n🔹 Realismo: simula lo que pasa en la práctica, cuando usamos el modelo para predecir casos que nunca había visto.\n🔹 Comparación: permite elegir entre varios modelos el que realmente generaliza mejor.\n\n# Dividimos nuestro dataset en dos partes: training y testing\nset.seed(2025)\nindex &lt;- initial_split(data)     \n# Crea un objeto que contiene la \"partición\" de los datos.\n# Por defecto, 75% de las filas se van al training y 25% al testing.\n# (Se puede ajustar con el argumento prop = 0.8, por ejemplo).\n\ntraining_data &lt;- training(index)  \n# Extrae del split anterior la parte de entrenamiento,\n# es decir, el subconjunto de datos que usaremos para\n# ajustar (entrenar) nuestro modelo.\n\ntesting_data &lt;- testing(index)    \n# Extrae del split anterior la parte de prueba,\n# es decir, el subconjunto de datos que NO verá el modelo\n# durante el entrenamiento y que servirá para evaluar\n# su capacidad de generalizar a datos nuevos.\n\nCómo vemos las particiones creadas?\n\ndim(training_data)\n\n[1] 59 15\n\n\n\ndim(testing_data)\n\n[1] 20 15\n\n\n\n\n7.4.3 Paso 3: Preprocesamiento de datos (Feature Engineering)\nEl paquete recipes de tidymodels permite definir de manera ordenada y reproducible los pasos de preprocesamiento de los datos antes de entrenar un modelo de machine learning.\nPrimero se define la receta principal de tu modelo, que identifica la variable predicha y las predictoras, similar a una ecuación. En este casos utilizamos esta fórmula:\n\\[\nVariablePredicha \\sim Predictor\n\\]\nLuego, si lo deseamos, podemos especificar qué transformaciones se aplicarán a las variables: desde tareas sencillas como eliminar valores perdidos o normalizar predictores, hasta imputaciones, creación de variables dummy o reducción de dimensionalidad. Cada transformación se añade como un step, y el flujo se encarga de aprender sus parámetros a partir del conjunto de entrenamiento y aplicarlos también al conjunto de prueba, evitando fugas de información (data leakage). De esta forma, recipes ofrece un marco flexible y seguro para preparar los datos de forma consistente en todo el proceso de modelado.\nPor el momento, vamos a definir nuestra receta:\n\nmi_receta &lt;- recipe(aml_index ~ pobreza, data = training_data)\n\nLuego de crear la receta, la podemos solicitar para ver qué es lo esta considerando:\n\nmi_receta\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 1\n\n\n\n\n\n\n\n\nNota\n\n\n\nMás adelante, en este paso también vamos a poder realizar algunas transformaciones dentro de nuestras variables. Por ejemplo:\n\nstep_naomit() → elimina filas con valores perdidos.\nstep_meanimpute() / step_medianimpute() → imputan NA con la media o mediana.\nstep_modeimpute() → imputación de NA con la moda en variables categóricas.\nstep_dummy() → convierte variables categóricas en variables dummy (0/1).\nstep_normalize() → estandariza predictores (media = 0, sd = 1).\nEntre otros.\n\n\n\n\n\n7.4.4 Paso 4: Seleccionamos el modelo\nEn la fase de modelamiento, el primer paso es definir el modelo que utilizaremos. En este caso empleamos linear_reg(), que especifica una regresión lineal, y le asignamos un motor de cálculo mediante set_engine(“lm”).\n\nmi_modelo_lm &lt;- linear_reg() |&gt; \n                   set_engine(\"lm\")\n\n\n\n7.4.5 Paso 5: Entrenamos el modelo\nA continuación, iniciamos un workflow(), que es una estructura de tidymodels diseñada para integrar en un solo flujo el preprocesamiento de datos (receta) y el entrenamiento. Esto garantiza que todo el proceso se ejecute de manera ordenada, reproducible y sin fugas de información. Añadimos al workflow tanto la receta definida en la etapa de preprocesamiento como el modelo lineal.\n\nflujo_ml&lt;-workflow() |&gt; \n            add_recipe(mi_receta) |&gt; \n             add_model(mi_modelo_lm)\nflujo_ml\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nFinalmente, y entrenamos este flujo con los datos de entrenamiento. De esta manera, se obtiene un objeto ajustado que estará listo para realizar predicciones y ser evaluado en el conjunto de prueba.\n\nmodelo_entrenado &lt;- flujo_ml %&gt;% \n                      fit(data = training_data) # Con el de ENTRENAMIENTO!\n\nSi deseamos ver los coeficientes (estimates) del modelo podemos solicitarlo con tidy():\n\ntidy(modelo_entrenado)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   4.27     0.221       19.3  1.04e-26\n2 pobreza       0.0405   0.00770      5.26 2.23e- 6\n\n\nEntonces, en este caso el modelo para la predicción del AML_index sería el siguiente:\n\\[\nAML = 4.27 + 0.04 * POBREZA\n\\]\n\n\n7.4.6 Paso 6: Evaluamos el modelo\nUna vez que el modelo ha sido entrenado, el siguiente paso es evaluar su desempeño. La evaluación consiste en medir qué tan bien el modelo logra predecir los valores de la variable de interés, comparando las predicciones con los valores reales. Para ello se utilizan métricas de error, como el RMSE (Root Mean Squared Error), que nos permiten cuantificar la calidad del ajuste y, sobre todo, estimar su capacidad de generalización cuando se aplica a nuevos datos.\nPara ello, primero utilizamos el modelo generado para predecir con la nueva data:\n\nprediccion_test&lt;-modelo_entrenado |&gt; \n                  predict(testing_data) |&gt; \n                  bind_cols(valor_real=testing_data$aml_index)\nprediccion_test\n\n# A tibble: 20 × 2\n   .pred valor_real\n   &lt;dbl&gt;      &lt;dbl&gt;\n 1  4.85       4.75\n 2  4.89       4.13\n 3  4.76       5.89\n 4  5.49       6.75\n 5  5.51       5.21\n 6  5.13       3   \n 7  6.18       7.69\n 8  4.85       4.9 \n 9  6.47       7.17\n10  5.17       3.47\n11  7.14       7.43\n12  6.33       5.63\n13  6.15       5.21\n14  5.19       4.81\n15  5.87       5.23\n16  4.84       3.57\n17  5.13       3.96\n18  4.54       4.05\n19  6.51       6.95\n20  4.43       5.08\n\n\nAhora vamos a medir cómo funciona nuestro modelo utilizándolo con data de testeo. Recuerda que en nuestra data de testeo podemos validar en contraste con el valor real.\n\nyardstick::rmse(prediccion_test,\n    truth = valor_real,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.990\n\n\nEl R cuadrado es otra medida, aunque menos utilizada en machine learning, que dice cuánto es explicado por nuestro modelo.\n\nrsq(prediccion_test,\n    truth = valor_real,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.512\n\n\nGraficamos:\n\nprediccion_test |&gt; \n  ggplot()+\n  aes(x = valor_real, y = .pred)+\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    x = \"Valor real\",\n    y = \"Valor predicho\",\n    title = \"Valores reales vs predicciones\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nPaso 7: Colocamos el modelo en operación\nSi lo que queremos es identificar con este modelo el aml_index perdido de la data inicial, cuál sería nuestra predicción?\n\nmodelo_entrenado |&gt; \n                  predict(aml_faltante) |&gt; \n                  bind_cols(aml_faltante$pais)\n\nNew names:\n• `` -&gt; `...2`\n\n\n# A tibble: 16 × 2\n   .pred ...2                    \n   &lt;dbl&gt; &lt;chr&gt;                   \n 1  6.48 Afghanistan             \n 2  5.32 Argentina               \n 3  5.94 Belize                  \n 4  4.44 Brazil                  \n 5  6.89 Burundi                 \n 6  6.79 Central African Republic\n 7  6.09 Comoros                 \n 8  5.21 Djibouti                \n 9  5.60 El Salvador             \n10  6.30 Eritrea                 \n11  5.69 Guyana                  \n12  5.16 India                   \n13  6.58 Lesotho                 \n14  5.30 Nepal                   \n15  5.77 Papua New Guinea        \n16  5.86 Rwanda",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ML Supervisado: Regresión lineal</span>"
    ]
  },
  {
    "objectID": "2_c3_rl.html#tidymodels",
    "href": "2_c3_rl.html#tidymodels",
    "title": "7  ML Supervisado: Regresión lineal",
    "section": "7.2 Tidymodels",
    "text": "7.2 Tidymodels\ntidymodels es un conjunto de paquetes de R diseñado para facilitar el trabajo con Machine Learning (ML) dentro de un marco coherente y organizado. Su objetivo es estandarizar el proceso de modelado, desde la preparación de datos hasta la evaluación de resultados, utilizando la misma filosofía del tidyverse: funciones consistentes, sintaxis clara y un enfoque centrado en los datos como tablas (tibbles).\n\nEl trabajo en ML no se limita a entrenar un modelo; incluye varios pasos que deben estar bien estructurados:\n\nPreparación de datos: limpieza, creación de variables y transformación de predictores.\nDefinición del modelo: especificar qué tipo de algoritmo se va a usar (regresión, árboles de decisión, random forest, etc.).\nEntrenamiento y validación: ajustar el modelo con los datos de entrenamiento y probarlo con datos nuevos para evitar sobreajuste.\nEvaluación: medir el desempeño con métricas como RMSE, MAE o accuracy.\nComparación: contrastar distintos modelos bajo un mismo flujo de trabajo.\n\nTidymodels organiza todo este proceso bajo un flujo reproducible y consistente, lo que permite:\n\nReducir errores en la preparación de datos.\nComparar modelos con facilidad.\nMantener el código ordenado y entendible.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ML Supervisado: Regresión lineal</span>"
    ]
  },
  {
    "objectID": "2_c4_rl2.html",
    "href": "2_c4_rl2.html",
    "title": "8  Preprocesamiento y validación cruzada",
    "section": "",
    "text": "8.1 Punto de partida\nHabíamos establecido en la clase anterior que queríamos utilizar nuestra data para construir buenos modelos predictivos SUPERVISADOS y para eso utilizamos la regresión lineal.\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_ix_i\n\\]\nTambién, acuérdate que utilizamos una función de costo principalmente para evaluar la predicción, la cual era el RMSE (raíz del error cuadrático medio):\n\\[\nJ(\\beta) \\;=\\; \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_i - \\hat{y}_i\\big)^2}\n\\]\nAsimismo, lo que hicimos en el ejercicio fue construir modelos con el nivel de pobreza (pobreza) y el PBI per cápita (pbi_pc)\nVamos a expandir nuestro uso de tidymodels.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preprocesamiento y validación cruzada</span>"
    ]
  },
  {
    "objectID": "2_c4_rl2.html#preprocesamiento-con-recipe",
    "href": "2_c4_rl2.html#preprocesamiento-con-recipe",
    "title": "8  Preprocesamiento y validación cruzada",
    "section": "8.2 Preprocesamiento con recipe",
    "text": "8.2 Preprocesamiento con recipe\n\nCon recipe no solo definimos la variable objetivo y los predictores; también podemos encadenar, de forma ordenada y reproducible, los pasos de preprocesamiento que aplicaremos al conjunto de datos (imputación, codificación, escalado, etc.).\nVamos a revisar los más recurrente.\n\n8.2.1 step_impute_mean(): Imputación de NA\n\nUtilizamos nuestra base de datos:\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\ndata &lt;- read_xlsx(\"data/AML_2.xlsx\")\ndata&lt;- data |&gt; \n        filter(!is.na(aml_index))\n\nImagina que ahora deseo utilizar rule_of_law como un predictor pero me doy cuenta que tiene valores perdidos.\n\nsummary(data$rule_of_law)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.3458  0.4432  0.5147  0.5549  0.6647  0.8995       9 \n\n\nHay que identificar si es que efectivamente es posible imputar:\n\nlibrary(naniar)\ndata |&gt; \n  vis_miss()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nLa imputación de datos perdidos es el proceso de reemplazar valores faltantes (NA) por valores plausibles para poder analizar y modelar sin descartar observaciones. Busca preservar el tamaño muestral, reducir sesgos y permitir que los algoritmos funcionen (muchos no aceptan NA).\nGuíate con estos criterios. Nos importa analizar por variable.\n\nPorcentaje BAJO (&lt;5%):Puedes eliminar esas filas sin perder mucha información o imputar.\nPorcentaje MEDIO (5-20%): Conviene imputar.\nPorcentaje ALTO (&gt;30%): Esa variable podría ser candidata a eliminarse, salvo que tenga relevancia en el análisis.\n\n\n\nLa imputación debe aplicarse siempre, SIEMPRE, sobre la data de entrenamiento.\n\nset.seed(2025)\nindex &lt;- initial_split(data)     \ntraining_data &lt;- training(index)  \ntesting_data &lt;- testing(index)    \n\nEntonces:\n\nmi_receta &lt;- recipe(aml_index ~ rule_of_law, data = training_data) |&gt; \n              step_impute_mean(rule_of_law)\n\n¿Qué es lo que está haciendo esta función? step_impute_mean() imputa los valores faltantes de variables numéricas con la media calculada en el conjunto de entrenamiento. Es decir, con este paso, nos va a permitir utilizar TODOS LOS CASOS, los cual al inicio tenía perdidos. Este es uno de los métodos de imputación más simples.\nAhora bien, antes de seguir, si quieres ver qué hace este step a nuestra data, podemos inspeccionarlo preparando la receta solo con el conjunto de entrenamiento (ahí la receta “aprende” parámetros como las medias) y luego mirar el entrenamiento ya transformado con juice() y el conjunto de prueba horneado con bake().\nEn la jerga de tidymodels, hornear significa aplicar a datos nuevos (p. ej., el test) exactamente las mismas transformaciones que se estimaron con el train —imputar con las medias del train, escalar con sus desvíos, crear las mismas dummies, etc.— sin recalcular nada y sin modificar tu objeto original; bake() simplemente devuelve un tibble ya transformado, listo para predecir.\nEsto aplica tanto en nuestro training data:\n\ntraining_data |&gt; \n  select(rule_of_law)\n\n# A tibble: 59 × 1\n   rule_of_law\n         &lt;dbl&gt;\n 1      NA    \n 2       0.703\n 3       0.534\n 4       0.834\n 5       0.569\n 6      NA    \n 7       0.630\n 8       0.556\n 9       0.800\n10       0.549\n# ℹ 49 more rows\n\n\nQue ahora se vería así:\n\nmi_receta |&gt; \n     prep() |&gt; # es cuando la receta aprende con el train\n     juice()   # devuelve el train ya transformado según lo aprendido en prep\n\n# A tibble: 59 × 2\n   rule_of_law aml_index\n         &lt;dbl&gt;     &lt;dbl&gt;\n 1       0.557      8.14\n 2       0.703      4.3 \n 3       0.534      4.71\n 4       0.834      4.29\n 5       0.569      5.85\n 6       0.557      4.7 \n 7       0.630      4.9 \n 8       0.556      5.16\n 9       0.800      4.1 \n10       0.549      5.29\n# ℹ 49 more rows\n\n\nComo en nuestro testing data, que antes se veía así:\n\ntesting_data |&gt; \n  select(rule_of_law)\n\n# A tibble: 20 × 1\n   rule_of_law\n         &lt;dbl&gt;\n 1       0.484\n 2       0.784\n 3      NA    \n 4       0.354\n 5       0.488\n 6       0.817\n 7       0.413\n 8       0.548\n 9       0.437\n10       0.768\n11       0.430\n12       0.522\n13       0.417\n14       0.486\n15      NA    \n16       0.688\n17       0.721\n18      NA    \n19       0.454\n20       0.485\n\n\nPero luego de aplicar la receta vamos a ver:\n\nmi_receta |&gt; \n      prep() |&gt; # es cuando la receta aprende con el train\n      bake(new_data=testing_data) # devuelve el test ya transformado según lo aprendido en prep\n\n# A tibble: 20 × 2\n   rule_of_law aml_index\n         &lt;dbl&gt;     &lt;dbl&gt;\n 1       0.484      4.75\n 2       0.784      4.13\n 3       0.557      5.89\n 4       0.354      6.75\n 5       0.488      5.21\n 6       0.817      3   \n 7       0.413      7.69\n 8       0.548      4.9 \n 9       0.437      7.17\n10       0.768      3.47\n11       0.430      7.43\n12       0.522      5.63\n13       0.417      5.21\n14       0.486      4.81\n15       0.557      5.23\n16       0.688      3.57\n17       0.721      3.96\n18       0.557      4.05\n19       0.454      6.95\n20       0.485      5.08\n\n\n\n\n8.2.2 step_normalize(): Normalizar variables\nDefinición\nEstandariza variables numéricas mediante z-score: a cada columna seleccionada le resta su media y la divide por su desviación estándar.\n\nCuándo usarlo:\n\nModelos sensibles a la escala o basados en distancia: k-NN, SVM, regresiones penalizadas (glmnet: Lasso/Ridge/Elastic Net), redes neuronales.\nNo es necesario para árboles, random forest o boosting basados en árboles.\n\nRecuerda que debes hacer esto a las variables numéricas.\nDespués de normalizar verás:\n\nLos números cambian de escala: cada predictor numérico queda con media ≈ 0 y desviación estándar ≈ 1. Verás muchos valores negativos (por debajo del promedio) y positivos (por encima).\nLas unidades desaparecen: ya no están en soles, años o %; ahora todos están en “desviaciones estándar”, por eso son comparables entre sí.\nLas formas no se rompen: el orden de los casos no cambia y las correlaciones entre variables se conservan; solo cambia la escala.\nEn tablas/gráficos: histogramas centrados en 0; resúmenes tipo mean ~ 0 y sd ~ 1. Si haces scatterplots, la nube luce igual, pero con ejes reescalados.\nEn el modelo: algoritmos sensibles a escala (k-NN, SVM, Lasso/Ridge/Elastic Net, PCA, k-means) se vuelven más estables y los coeficientes en modelos lineales son más comparables en magnitud.\n\nEjemplo simple\nVeamos lo que hacemos con un ejemplo:\n\ndf2 &lt;- tibble(\n  edad   = c(22, 25, 28, 30, 34, 37, 41, 45, 52, 58),\n  sueldo = c(1200, 1350, 1500, 1650, 2100, 2400, 3000, 3500, 4200, 5000)\n)\n\nNormalizar implica:\n\ndf2 &lt;- df2 |&gt; \n  mutate(edad_normalizado=(edad-mean(edad))/sd(edad), \n         sueldo_normalizado=(sueldo-mean(sueldo))/sd(sueldo))\ndf2\n\n# A tibble: 10 × 4\n    edad sueldo edad_normalizado sueldo_normalizado\n   &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt;              &lt;dbl&gt;\n 1    22   1200          -1.29               -1.07 \n 2    25   1350          -1.03               -0.954\n 3    28   1500          -0.780              -0.838\n 4    30   1650          -0.610              -0.723\n 5    34   2100          -0.271              -0.377\n 6    37   2400          -0.0169             -0.146\n 7    41   3000           0.322               0.315\n 8    45   3500           0.661               0.700\n 9    52   4200           1.25                1.24 \n10    58   5000           1.76                1.85 \n\n\nEntonces, ahora la escala cambia y son comparables:\n\nsummary(df2$edad_normalizado)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-1.2879 -0.7372 -0.1440  0.0000  0.5762  1.7624 \n\n\n\nsummary(df2$sueldo_normalizado)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-1.0691 -0.8095 -0.2615  0.0000  0.6038  1.8536 \n\n\nAplicación con tidymodels\nEsto que hemos hecho manualmente, también lo podemos hacer con tidymodels y la función step_normalize(). Piensa en las variables rule_of_law y cpi_index.\n\nmi_receta &lt;- recipe(aml_index ~ rule_of_law + pbi_pc, data = training_data) |&gt; \n              step_impute_mean(rule_of_law) |&gt; \n              step_normalize(pbi_pc)\n\nVemos nuestro dataset de entrenamiento:\n\nmi_receta |&gt; \n     prep() |&gt; # es cuando la receta aprende con el train\n     juice()   # devuelve el train ya transformado según lo aprendido en prep\n\n# A tibble: 59 × 3\n   rule_of_law  pbi_pc aml_index\n         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1       0.557 -0.746       8.14\n 2       0.703  2.95        4.3 \n 3       0.534 -0.208       4.71\n 4       0.834  2.04        4.29\n 5       0.569 -0.411       5.85\n 6       0.557 -0.417       4.7 \n 7       0.630 -0.0594      4.9 \n 8       0.556 -0.231       5.16\n 9       0.800  2.26        4.1 \n10       0.549 -0.659       5.29\n# ℹ 49 more rows\n\n\nY nuestor dataset de test:\n\nmi_receta |&gt; \n      prep() |&gt; # es cuando la receta aprende con el train\n      bake(new_data=testing_data) # devuelve el test ya transformado según lo aprendido en prep\n\n# A tibble: 20 × 3\n   rule_of_law pbi_pc aml_index\n         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1       0.484 -0.479      4.75\n 2       0.784  2.02       4.13\n 3       0.557 -0.580      5.89\n 4       0.354 -0.699      6.75\n 5       0.488 -0.335      5.21\n 6       0.817  0.593      3   \n 7       0.413 -0.734      7.69\n 8       0.548 -0.538      4.9 \n 9       0.437 -0.764      7.17\n10       0.768  0.345      3.47\n11       0.430 -0.758      7.43\n12       0.522 -0.766      5.63\n13       0.417 -0.213      5.21\n14       0.486 -0.377      4.81\n15       0.557  0.184      5.23\n16       0.688  0.757      3.57\n17       0.721  1.02       3.96\n18       0.557  4.13       4.05\n19       0.454 -0.751      6.95\n20       0.485 -0.614      5.08\n\n\n\n\n8.2.3 step_dummy(): Predictoras categóricas\nDefinición\nPara usar variables categóricas en muchos algoritmos de aprendizaje (por ejemplo, regresiones penalizadas como glmnet, SVM, redes, XGBoost), primero hay que convertirlas a variables numéricas. La forma estándar es el one-hot encoding: cada categoría de una variable se transforma en una columna binaria que vale 1 si el registro pertenece a esa categoría y 0 si no.\n\nPor ejemplo, si color tiene valores (rojo, azul, verde), se crean columnas como color_rojo, color_azul y color_verde. Esto permite que el modelo “entienda” información categórica sin asignar números arbitrarios que introducirían un orden falso.\nEjemplo simple\nHagamos un ejemplo básico:\n\ndf &lt;- tibble(\n  id     = 1:5,\n  edad   = c(15,21,30,57,62),\n  sector = c(\"publico\", \"privado\", \"publico\", \"privado\", \"privado\"))\ndf\n\n# A tibble: 5 × 3\n     id  edad sector \n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n1     1    15 publico\n2     2    21 privado\n3     3    30 publico\n4     4    57 privado\n5     5    62 privado\n\n\nConvertir a dummy, significa que vamos a:\n\ndf |&gt; \n  mutate(sector_public=ifelse(sector==\"publico\", 1, 0),\n         sector_privado=ifelse(sector==\"privado\", 1, 0))\n\n# A tibble: 5 × 5\n     id  edad sector  sector_public sector_privado\n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1     1    15 publico             1              0\n2     2    21 privado             0              1\n3     3    30 publico             1              0\n4     4    57 privado             0              1\n5     5    62 privado             0              1\n\n\nComo ves en este ejemplo, a la derecha hemos creado dos nuevas variables “sector_publico” que coloca un “1” cuando efectivamente el caso pertenece a ese sector y “sector_privado” cuando ocurre lo propio. En caso no se cumpla la condición, existirá un cero.\nAplicación con tidymodels\nAhora bien, podemos hacer esta transformación de una forma más sencilla utilizando recipes.\n\nmi_receta &lt;- recipe(aml_index ~ rule_of_law + pbi_pc + continente, data = training_data) |&gt; \n              step_impute_mean(rule_of_law) |&gt; \n              step_normalize(pbi_pc, rule_of_law) |&gt; \n              step_dummy(continente)\n\nAhora vemos cómo se vería nuestra data de entrenamiento.\n\nmi_receta |&gt; \n     prep() |&gt; # es cuando la receta aprende con el train\n     juice()\n\n# A tibble: 59 × 7\n   rule_of_law  pbi_pc aml_index continente_Americas continente_Asia\n         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt;           &lt;dbl&gt;\n 1     0       -0.746       8.14                   0               0\n 2     1.10     2.95        4.3                    1               0\n 3    -0.179   -0.208       4.71                   0               1\n 4     2.08     2.04        4.29                   0               0\n 5     0.0895  -0.411       5.85                   0               0\n 6     0       -0.417       4.7                    0               0\n 7     0.549   -0.0594      4.9                    0               0\n 8    -0.00893 -0.231       5.16                   0               0\n 9     1.82     2.26        4.1                    0               0\n10    -0.0636  -0.659       5.29                   0               0\n# ℹ 49 more rows\n# ℹ 2 more variables: continente_Europe &lt;dbl&gt;, continente_Oceania &lt;dbl&gt;\n\n\nY nuestra data de testing:\n\nmi_receta |&gt; \n      prep() |&gt; # es cuando la receta aprende con el train\n      bake(new_data=testing_data) # devuelve el test ya transformado según lo aprendido en prep\n\n# A tibble: 20 × 7\n   rule_of_law pbi_pc aml_index continente_Americas continente_Asia\n         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt;           &lt;dbl&gt;\n 1     -0.551  -0.479      4.75                   0               0\n 2      1.70    2.02       4.13                   0               0\n 3      0      -0.580      5.89                   0               1\n 4     -1.53   -0.699      6.75                   0               0\n 5     -0.522  -0.335      5.21                   1               0\n 6      1.95    0.593      3                      0               0\n 7     -1.09   -0.734      7.69                   0               0\n 8     -0.0721 -0.538      4.9                    0               1\n 9     -0.904  -0.764      7.17                   0               0\n10      1.58    0.345      3.47                   0               0\n11     -0.959  -0.758      7.43                   0               0\n12     -0.268  -0.766      5.63                   0               0\n13     -1.05   -0.213      5.21                   1               0\n14     -0.535  -0.377      4.81                   1               0\n15      0       0.184      5.23                   0               0\n16      0.979   0.757      3.57                   0               0\n17      1.23    1.02       3.96                   0               0\n18      0       4.13       4.05                   0               0\n19     -0.779  -0.751      6.95                   0               0\n20     -0.542  -0.614      5.08                   0               0\n# ℹ 2 more variables: continente_Europe &lt;dbl&gt;, continente_Oceania &lt;dbl&gt;",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preprocesamiento y validación cruzada</span>"
    ]
  },
  {
    "objectID": "2_c4_rl2.html#regresión-lineal-con-receta",
    "href": "2_c4_rl2.html#regresión-lineal-con-receta",
    "title": "8  Preprocesamiento y validación cruzada",
    "section": "8.3 Regresión lineal con receta",
    "text": "8.3 Regresión lineal con receta\n\n8.3.1 Probando la nueva receta\nRecapitulamos la receta que tenemos con preprocesamiento:\n\nmi_receta\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 3\n\n\n\n\n\n── Operations \n\n\n• Mean imputation for: rule_of_law\n\n\n• Centering and scaling for: pbi_pc rule_of_law\n\n\n• Dummy variables from: continente\n\n\nGeneramos nuestro modelo:\n\nmi_modelo_lm &lt;- linear_reg() |&gt; \n                   set_engine(\"lm\")\n\nflujo_ml&lt;-workflow() |&gt; \n            add_recipe(mi_receta) |&gt; \n             add_model(mi_modelo_lm)\n\nmodelo_entrenado &lt;- flujo_ml %&gt;% \n                      fit(data = training_data) # Con el de ENTRENAMIENTO!\n\nSi deseamos ver los coeficientes (estimates) del modelo podemos solicitarlo con tidy():\n\ntidy(modelo_entrenado)\n\n# A tibble: 7 × 5\n  term                estimate std.error statistic  p.value\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)           6.12       0.172    35.7   3.20e-38\n2 rule_of_law          -0.441      0.154    -2.87  5.88e- 3\n3 pbi_pc               -0.0921     0.159    -0.580 5.65e- 1\n4 continente_Americas  -1.14       0.242    -4.70  1.95e- 5\n5 continente_Asia      -1.00       0.235    -4.26  8.58e- 5\n6 continente_Europe    -1.31       0.274    -4.79  1.45e- 5\n7 continente_Oceania   -0.600      0.460    -1.30  1.98e- 1\n\n\nQué puedes notar en los coeficientes?\n\n\n8.3.2 Evaluamos el modelo con test\nUna vez que el modelo ha sido entrenado, el siguiente paso es evaluar su desempeño. La evaluación consiste en medir qué tan bien el modelo logra predecir los valores de la variable de interés, comparando las predicciones con los valores reales. Para ello se utilizan métricas de error, como el RMSE (Root Mean Squared Error), que nos permiten cuantificar la calidad del ajuste y, sobre todo, estimar su capacidad de generalización cuando se aplica a nuevos datos.\nPara ello, primero utilizamos el modelo generado para predecir con la nueva data:\n\nprediccion_test&lt;-modelo_entrenado |&gt; \n                  predict(testing_data) |&gt; \n                  bind_cols(valor_real=testing_data$aml_index)\nprediccion_test\n\n# A tibble: 20 × 2\n   .pred valor_real\n   &lt;dbl&gt;      &lt;dbl&gt;\n 1  5.10       4.75\n 2  3.87       4.13\n 3  5.18       5.89\n 4  6.86       6.75\n 5  5.24       5.21\n 6  3.90       3   \n 7  6.67       7.69\n 8  5.20       4.9 \n 9  6.59       7.17\n10  4.08       3.47\n11  6.62       7.43\n12  6.31       5.63\n13  5.47       5.21\n14  5.25       4.81\n15  6.11       5.23\n16  4.31       3.57\n17  4.17       3.96\n18  4.43       4.05\n19  6.54       6.95\n20  5.11       5.08\n\n\nAhora vamos a medir cómo funciona nuestro modelo utilizándolo con data de testeo. Recuerda que en nuestra data de testeo podemos validar en contraste con el valor real.\n\nyardstick::rmse(prediccion_test,\n    truth = valor_real,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.567\n\n\nEl R cuadrado es otra medida, aunque menos utilizada en machine learning, que dice cuánto es explicado por nuestro modelo.\n\nrsq(prediccion_test,\n    truth = valor_real,\n    estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.867\n\n\nGraficamos:\n\nprediccion_test |&gt; \n  ggplot()+\n  aes(x = valor_real, y = .pred)+\n  geom_point(color = \"blue\", size = 2) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +  # línea 1:1\n  labs(\n    x = \"Valor real\",\n    y = \"Valor predicho\",\n    title = \"Valores reales vs predicciones\"\n  ) +\n  xlim(0,10)+ ylim(0,10)+\n  theme_minimal()",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preprocesamiento y validación cruzada</span>"
    ]
  },
  {
    "objectID": "2_c4_rl2.html#remuestreo-para-evaluar-el-rendimiento-cross-validation",
    "href": "2_c4_rl2.html#remuestreo-para-evaluar-el-rendimiento-cross-validation",
    "title": "8  Preprocesamiento y validación cruzada",
    "section": "8.4 Remuestreo para evaluar el rendimiento: cross-validation",
    "text": "8.4 Remuestreo para evaluar el rendimiento: cross-validation\nHasta aquí te había comentado que era necesario separar nuestra data en data de entrenamiento (train) y data de evaluación (test).\n\nSin embargo, el depender de un único split (partición) es un riesgo para nosotros. Si te pones a pensar es como evaluar a un deportista con una sóla carrera. En otras palabras, la “nota” del modelo queda a merced del azar del muestreo. Por eso, se establece que antes de irnos a evaluar al modelo con el testing dataset debe pasar por un proceso de validación.\nEste proceso de validación requeriría hacer un split adicional. Normalmente, en un escenario óptimo, vamos a tener la suficiente cantidad de información para crear una partición más.\n\nSin embargo, lo que usualmente ocurre es que no se cuenta con la suficiente cantidad de información. Esto nos deja una salida: usar una técnica que se llama cross-validation o validación cruzada.\n\nLa idea detrás del remuestreo es usar tu muestra disponible como si fuera el universo para simular muchos “nuevos” conjuntos de datos y así estimar con mayor fiabilidad cómo rendiría un modelo o un estimador fuera de esa muestra. En vez de depender de un único corte train/test (muy sensible al azar), divides o vuelves a muestrear tus datos muchas veces, entrenas y evalúas repetidamente, y promedias los resultados.\nPrimero debemos crear nuestras particiones utilizando nuestro training data. En este caso vamos a comenzar utilizando sólo cuatro particiones o folds.\n\nset.seed(2025)\nfolds &lt;- vfold_cv(training_data, v= 4)\n\nSi entramos a nuestro primer fold, vemos que hemos divido la data de entrenamiento (59) en dos partes. Una primera que fungirá como data para analizar nuestro modelo (aquí para evitar la confusión con el término entrenamiento, se utiliza la palabra analysis) y un fold de 15 casos para el assess.\n\nfolds$splits[[1]]\n\n&lt;Analysis/Assess/Total&gt;\n&lt;44/15/59&gt;\n\n\nPara correr nuevamente nuestro modelo utilizando cross-validation necesitamos seguir los mismos pasos del workflow, pero utilizando el fit en las nuevas particiones:\n\nmi_modelo_lm &lt;- linear_reg() |&gt; \n                   set_engine(\"lm\")\n\nflujo_ml&lt;-workflow() |&gt; \n            add_recipe(mi_receta) |&gt; \n             add_model(mi_modelo_lm)\n\nmodelos_entrenados_cv &lt;- flujo_ml %&gt;% \n                          fit_resamples(resamples = folds) #DIFERENTE\n\n→ A | warning: ! There are new levels in `continente`: \"Oceania\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n\nAhora, podemos solicitar las métricas para cada uno de los folds creado:\n\nmodelos_entrenados_cv |&gt; \n  collect_metrics(summarize = FALSE)\n\n# A tibble: 8 × 5\n  id    .metric .estimator .estimate .config             \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 Fold1 rmse    standard       0.682 Preprocessor1_Model1\n2 Fold1 rsq     standard       0.756 Preprocessor1_Model1\n3 Fold2 rmse    standard       0.430 Preprocessor1_Model1\n4 Fold2 rsq     standard       0.811 Preprocessor1_Model1\n5 Fold3 rmse    standard       0.656 Preprocessor1_Model1\n6 Fold3 rsq     standard       0.803 Preprocessor1_Model1\n7 Fold4 rmse    standard       0.637 Preprocessor1_Model1\n8 Fold4 rsq     standard       0.589 Preprocessor1_Model1\n\n\nFinalmente, solicitamos el promedio:\n\nmodelos_entrenados_cv |&gt; \n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.601     4  0.0577 Preprocessor1_Model1\n2 rsq     standard   0.740     4  0.0518 Preprocessor1_Model1\n\n\nEste fit_samples se recomienda hacerlo antes del fit con la data de testeo. De tal forma que antes de la evaluación, ya sabes que tu modelo puede funcionar con distintos subdataset creados a partir de tu data de entrenamiento original.",
    "crumbs": [
      "R Intermedio",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Preprocesamiento y validación cruzada</span>"
    ]
  }
]